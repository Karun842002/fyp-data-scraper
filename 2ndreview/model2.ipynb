{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-addons  # version >= 0.15.0 is required\n",
        "!pip install -q tensorflow\n",
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "ByeNI04wmU8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import datasets"
      ],
      "metadata": {
        "id": "59U0Tz4JmWTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_SIZE = 2\n",
        "VOCAB_SIZE = 20000"
      ],
      "metadata": {
        "id": "c5u1r9-7mrwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def create_data_generatorr(dataset):\n",
        "  def data_generator():\n",
        "    for i in range(len(dataset)):\n",
        "      left = dataset.loc[i]['x'].split(' ')\n",
        "      right = None\n",
        "      if dataset.loc[i]['y'] == 0:\n",
        "        right = [0 for i in range(len(left))]\n",
        "      else:\n",
        "        right = [1 for i in range(len(left))]\n",
        "      yield left, right\n",
        "  \n",
        "  return data_generator\n",
        "\n",
        "df = pd.read_csv('/content/cleaned2.csv')\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['truth_value'] = le.fit_transform(df['truth_value'])\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(df['claim'], df['truth_value'], test_size=0.2, random_state=42)\n",
        "\n",
        "train = pd.concat({'x': xtrain, 'y': ytrain}, axis=1)\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "splittrain = train['x'].apply(lambda x: x.split(' '))\n",
        "xtrain_tokens = tf.ragged.constant(train['x'].apply(lambda x: x.split(' ')))\n",
        "xtrain_tokens = tf.map_fn(tf.strings.lower, xtrain_tokens)\n",
        "\n",
        "trainlookup_layer = tf.keras.layers.StringLookup(max_tokens=VOCAB_SIZE, mask_token=\"[MASK]\", oov_token=\"[UNK]\")\n",
        "trainlookup_layer.adapt(xtrain_tokens)\n",
        "\n",
        "\n",
        "data_signature= (\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(None, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "train_data = tf.data.Dataset.from_generator(\n",
        "    create_data_generatorr(train),\n",
        "    output_signature=data_signature\n",
        ")"
      ],
      "metadata": {
        "id": "5y2LmfWfpw9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainlookup_layer.get_vocabulary(include_special_tokens=True)"
      ],
      "metadata": {
        "id": "che3CaiH-1ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = [i.decode('UTF-8') for i in trainlookup_layer.get_weights()[0]]\n",
        "with open('z.txt', 'w') as file:\n",
        "  file.write(trainlookup_layer.get_vocabulary(include_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "l8mkgpUn3AH9",
        "outputId": "c19f7763-fbb9-465d-9a03-7b1ffe547e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e41b89f6fd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# x = [i.decode('UTF-8') for i in trainlookup_layer.get_weights()[0]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'z.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainlookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def create_data_generatorr(dataset):\n",
        "  def data_generator():\n",
        "    for i in range(len(dataset)):\n",
        "      left = dataset.loc[i]['x'].split(' ')\n",
        "      right = None\n",
        "      if dataset.loc[i]['y'] == 0:\n",
        "        right = [0 for i in range(len(left))]\n",
        "      else:\n",
        "        right = [1 for i in range(len(left))]\n",
        "      yield left, right\n",
        "  \n",
        "  return data_generator\n",
        "\n",
        "df = pd.read_csv('/content/cleaned2.csv')\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['truth_value'] = le.fit_transform(df['truth_value'])\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(df['claim'], df['truth_value'], test_size=0.2, random_state=42)\n",
        "\n",
        "train = pd.concat({'x': xtrain, 'y': ytrain}, axis=1)\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test = pd.concat({'x': xtest, 'y': ytest}, axis=1)\n",
        "test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "splittrain = train['x'].apply(lambda x: x.split(' '))\n",
        "splittest = test['x'].apply(lambda x: x.split(' '))\n",
        "xtrain_tokens = tf.ragged.constant(train['x'].apply(lambda x: x.split(' ')))\n",
        "xtrain_tokens = tf.map_fn(tf.strings.lower, xtrain_tokens)\n",
        "xtest_tokens = tf.ragged.constant(test['x'].apply(lambda x: x.split(' ')))\n",
        "xtest_tokens = tf.map_fn(tf.strings.lower, xtest_tokens)\n",
        "\n",
        "trainlookup_layer = tf.keras.layers.StringLookup(max_tokens=VOCAB_SIZE, mask_token=\"[MASK]\", oov_token=\"[UNK]\")\n",
        "trainlookup_layer.adapt(xtrain_tokens)\n",
        "testlookup_layer = tf.keras.layers.StringLookup(max_tokens=VOCAB_SIZE, mask_token=\"[MASK]\", oov_token=\"[UNK]\")\n",
        "testlookup_layer.adapt(xtest_tokens)\n",
        "\n",
        "\n",
        "data_signature= (\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(None, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "train_data = tf.data.Dataset.from_generator(\n",
        "    create_data_generatorr(train),\n",
        "    output_signature=data_signature\n",
        ")\n",
        "test_data = tf.data.Dataset.from_generator(\n",
        "    create_data_generatorr(test),\n",
        "    output_signature=data_signature\n",
        ")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "3Dabc9ghlgSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(df['simple_sentence'], df['truth_value'], test_size=0.2, random_state=42)\n",
        "\n",
        "train = pd.concat({'x': xtrain, 'y': ytrain}, axis=1)\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test = pd.concat({'x': xtest, 'y': ytest}, axis=1)\n",
        "test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "splittrain = train['x'].apply(lambda x: x.split(' '))\n",
        "splittest = test['x'].apply(lambda x: x.split(' '))\n",
        "xtrain_tokens = tf.ragged.constant(train['x'].apply(lambda x: x.split(' ')))\n",
        "xtrain_tokens = tf.map_fn(tf.strings.lower, xtrain_tokens)\n",
        "xtest_tokens = tf.ragged.constant(test['x'].apply(lambda x: x.split(' ')))\n",
        "xtest_tokens = tf.map_fn(tf.strings.lower, xtest_tokens)\n",
        "\n",
        "trainlookup_layer = tf.keras.layers.StringLookup(max_tokens=VOCAB_SIZE, mask_token=\"[MASK]\", oov_token=\"[UNK]\")\n",
        "trainlookup_layer.adapt(xtrain_tokens)\n",
        "testlookup_layer = tf.keras.layers.StringLookup(max_tokens=VOCAB_SIZE, mask_token=\"[MASK]\", oov_token=\"[UNK]\")\n",
        "testlookup_layer.adapt(xtest_tokens)\n",
        "\n",
        "\n",
        "data_signature= (\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(None, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "train_data = tf.data.Dataset.from_generator(\n",
        "    create_data_generatorr(train),\n",
        "    output_signature=data_signature\n",
        ")\n",
        "test_data = tf.data.Dataset.from_generator(\n",
        "    create_data_generatorr(test),\n",
        "    output_signature=data_signature\n",
        ")"
      ],
      "metadata": {
        "id": "k3bL8c83X2GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xxtest = xtest.reset_index(drop=True)\n",
        "yytest = ytest.reset_index(drop=True)\n",
        "xxtest.loc[0], yytest.loc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weY05axDlgSm",
        "outputId": "d9181fd5-a096-4578-b704-dc59890bf94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The Pentagon prepares to send more weapons to Ukraine, and hundreds of Russians attend a memorial for propagandist Daria Dugina, who was killed in a car bombing.',\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xxxtest = pd.DataFrame({'x': xxtest}, columns=['x'])\n",
        "xxxtest"
      ],
      "metadata": {
        "id": "qLUCGvtEssNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for a, b in train_data:\n",
        "  print(' '.join([aa.decode('UTF-8') for aa in a.numpy()]), b)\n",
        "  i += 1\n",
        "  if i>10:\n",
        "    break"
      ],
      "metadata": {
        "id": "ZkPD725nlgSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_preprocess_train(tokens, tag_ids):\n",
        "    preprocessed_tokens = preprecess_tokens_test(tokens)\n",
        "    return preprocessed_tokens, tag_ids\n",
        "\n",
        "def preprecess_tokens_train(tokens):\n",
        "    tokens = tf.strings.lower(tokens)\n",
        "    return trainlookup_layer(tokens)\n",
        "\n",
        "def dataset_preprocess_test(tokens, tag_ids):\n",
        "    preprocessed_tokens = preprecess_tokens_test(tokens)\n",
        "    return preprocessed_tokens, tag_ids\n",
        "\n",
        "def preprecess_tokens_test(tokens):\n",
        "    tokens = tf.strings.lower(tokens)\n",
        "    return testlookup_layer(tokens)\n",
        "\n",
        "BATCH_SIZE = 2048\n",
        "\n",
        "train_dataset = (\n",
        "    train_data.map(dataset_preprocess_train)\n",
        "    .padded_batch(batch_size=BATCH_SIZE).cache()\n",
        ")\n",
        "test_dataset = (\n",
        "    test_data.map(dataset_preprocess_test)\n",
        "    .padded_batch(batch_size=BATCH_SIZE).cache()\n",
        ")\n"
      ],
      "metadata": {
        "id": "rmaZAjxrlgSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "def build_embedding_bilstm_crf_model(\n",
        "    vocab_size: int, embed_dims: int, lstm_unit: int, tag_size: int\n",
        ") -> tf.keras.Model:\n",
        "    x = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"x\")\n",
        "    y = tf.keras.layers.Embedding(vocab_size, embed_dims, mask_zero=True)(x)\n",
        "    y = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(lstm_unit, return_sequences=True)\n",
        "    )(y)\n",
        "    decode_sequence, potentials, sequence_length, kernel = tfa.layers.CRF(tag_size)(y)\n",
        "    return tf.keras.Model(\n",
        "        inputs=x, outputs=[decode_sequence, potentials, sequence_length, kernel]\n",
        "    )\n",
        "\n",
        "model = None\n",
        "optimizer = None"
      ],
      "metadata": {
        "id": "kywd6Tq1lgSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def crf_loss_func(potentials, sequence_length, kernel, y):\n",
        "    crf_likelihood, _ = tfa.text.crf_log_likelihood(\n",
        "        potentials, y, sequence_length, kernel\n",
        "    )\n",
        "    # likelihood to loss\n",
        "    flat_crf_loss = -1 * crf_likelihood\n",
        "    crf_loss = tf.reduce_mean(flat_crf_loss)\n",
        "\n",
        "    return crf_loss\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def train_step(x, y):\n",
        "    global cur\n",
        "    global model\n",
        "    global optimizer\n",
        "    with tf.GradientTape() as tape:\n",
        "        decoded_sequence, potentials, sequence_length, kernel = model(x)\n",
        "        crf_loss = crf_loss_func(potentials, sequence_length, kernel, y)\n",
        "        loss = crf_loss + tf.reduce_sum(model.losses)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n"
      ],
      "metadata": {
        "id": "seNDRjdIlgSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_embedding_bilstm_crf_model(VOCAB_SIZE, 32, 64, 2)\n",
        "optimizer = tf.keras.optimizers.Adam(0.02)\n",
        "\n",
        "\n",
        "for epoch in range(15):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "\n",
        "  for x, y in train_dataset:\n",
        "      print(x.shape)\n",
        "      train_step(x, y)\n",
        "      # train_step2(x, y)\n",
        "  print(f\"Epoch {epoch + 1}, \" f\"Loss: {train_loss.result()}\")\n",
        "\n",
        "\n",
        "      \n",
        "# model3.fit(x=o, y=oy, epochs=10)\n",
        "\n",
        "  # acc = 0\n",
        "  # counter = 0\n",
        "  # for i, row in tqdm(xxxtest.iterrows(), total=xxxtest.shape[0]):\n",
        "  #   tx = xxtest.loc[i]\n",
        "  #   ty = yytest.loc[i]\n",
        "  #   preprocessed_inputs = preprecess_tokens(tx.split(' '))\n",
        "  #   # expend the batch dim\n",
        "  #   inputs = tf.reshape(preprocessed_inputs, shape=[1, -1])\n",
        "\n",
        "  #   outputs, *_ = model.predict(inputs, verbose=0)\n",
        "  #   tot = (sum(outputs[0]) / len(outputs[0])) * 100\n",
        "  #   label = 1\n",
        "  #   if tot <= 50:\n",
        "  #     label = 0\n",
        "  #   # print(ty, label)\n",
        "  #   if ty == label:\n",
        "  #     acc += 1\n",
        "  #   # if counter > 100:\n",
        "  #   #   break\n",
        "  #   counter += 1\n",
        "  # acc /= len(xxtest)\n",
        "  # print('\\n', acc)\n",
        "  # cur += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "JMbONC6t128-",
        "outputId": "6f973ae3-45b2-4d29-df7e-e1a7ed7db66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2048, 70)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-0317616525e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0;31m# train_step2(x, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}, \"\u001b[0m \u001b[0;34mf\"Loss: {train_loss.result()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./m2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrgATYLXZoKI",
        "outputId": "ce21ff0e-9987-4273-e6c9-a2201fab3b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = tf.keras.models.load_model('m1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H5xBZQxajkX",
        "outputId": "a2efa39d-ea67-4c5b-e575-8fab45103da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o = []\n",
        "oy = []\n",
        "\n",
        "def processs(x, pred):\n",
        "  res = []\n",
        "  for i in range(len(x)):\n",
        "    b = pred[i]\n",
        "    tot = (sum(b) / len(b)) * 100\n",
        "    label = 1\n",
        "    if tot <= 50:\n",
        "      label = 0\n",
        "    res.append(label)\n",
        "  return res\n",
        "\n",
        "for x, y in train_dataset:\n",
        "  print(x.shape, y.shape)\n",
        "  # print(y, y.shape)\n",
        "  outputs1, *_ = m1.predict(x)\n",
        "  outputs2, *_ = model.predict(x)\n",
        "  a = processs(x.numpy(), outputs1)\n",
        "  b = processs(x.numpy(), outputs2)\n",
        "  o += zip(a, b)\n",
        "  oy += [p[0] for p in y.numpy()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcIHK8D8Nxcg",
        "outputId": "8682d03a-9cf8-4302-c7ba-31cf74be30c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2048, 390) (2048, 390)\n",
            "64/64 [==============================] - 20s 261ms/step\n",
            "64/64 [==============================] - 18s 243ms/step\n",
            "(2048, 489) (2048, 489)\n",
            "64/64 [==============================] - 24s 342ms/step\n",
            "64/64 [==============================] - 23s 321ms/step\n",
            "(1268, 222) (1268, 222)\n",
            "40/40 [==============================] - 8s 140ms/step\n",
            "40/40 [==============================] - 10s 153ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(o).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoGF4-FULUwp",
        "outputId": "38b933cd-4284-4305-bd56-a96c0240c4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5364, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to = []\n",
        "toy = []\n",
        "\n",
        "for x, y in test_dataset:\n",
        "  toy += [p[0] for p in y.numpy()]\n",
        "  to += [[p[0], p[0]] for p in y.numpy()]"
      ],
      "metadata": {
        "id": "nFcwEBf1Soyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(to).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyL5xtBJW00B",
        "outputId": "30cfd318-1a1e-4cd6-932d-76fc0fd0d722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1342, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "model4 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model4.fit(x=np.array(o), y=np.array(oy), validation_data=(np.array(to), np.array(toy)), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxJuPXZQKNIJ",
        "outputId": "73a64c77-5237-45da-d74f-80f5b0461430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "168/168 [==============================] - 1s 5ms/step - loss: 0.6670 - accuracy: 0.8466 - val_loss: 0.8963 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.6171 - accuracy: 0.8507 - val_loss: 0.7892 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.5760 - accuracy: 0.8523 - val_loss: 0.6998 - val_accuracy: 0.8405\n",
            "Epoch 4/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.5424 - accuracy: 0.8553 - val_loss: 0.6281 - val_accuracy: 0.8405\n",
            "Epoch 5/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.5151 - accuracy: 0.8553 - val_loss: 0.5702 - val_accuracy: 0.8405\n",
            "Epoch 6/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.4931 - accuracy: 0.8553 - val_loss: 0.5254 - val_accuracy: 0.8405\n",
            "Epoch 7/10\n",
            "168/168 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.8546 - val_loss: 0.4903 - val_accuracy: 0.8405\n",
            "Epoch 8/10\n",
            "168/168 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.8546 - val_loss: 0.4643 - val_accuracy: 0.8405\n",
            "Epoch 9/10\n",
            "168/168 [==============================] - 1s 5ms/step - loss: 0.4500 - accuracy: 0.8546 - val_loss: 0.4436 - val_accuracy: 0.8405\n",
            "Epoch 10/10\n",
            "168/168 [==============================] - 1s 5ms/step - loss: 0.4412 - accuracy: 0.8546 - val_loss: 0.4281 - val_accuracy: 0.8405\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55b77fa8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('fm.h5')"
      ],
      "metadata": {
        "id": "Un9cckGcb3s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "model5 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model5.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model5.fit(x=np.array(o), y=np.array(oy), validation_data=(np.array(to), np.array(toy)), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipWIXtUEXYxc",
        "outputId": "1284ee8d-f245-426f-fad8-017902a6580b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "168/168 [==============================] - 2s 5ms/step - loss: 0.5060 - accuracy: 0.8477 - val_loss: 0.2645 - val_accuracy: 0.8405\n",
            "Epoch 2/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3994 - accuracy: 0.8546 - val_loss: 0.3002 - val_accuracy: 0.8405\n",
            "Epoch 3/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8546 - val_loss: 0.2915 - val_accuracy: 0.8405\n",
            "Epoch 4/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3984 - accuracy: 0.8546 - val_loss: 0.2934 - val_accuracy: 0.8405\n",
            "Epoch 5/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3989 - accuracy: 0.8546 - val_loss: 0.2941 - val_accuracy: 0.8405\n",
            "Epoch 6/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3977 - accuracy: 0.8546 - val_loss: 0.2784 - val_accuracy: 0.8405\n",
            "Epoch 7/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3975 - accuracy: 0.8546 - val_loss: 0.2999 - val_accuracy: 0.8405\n",
            "Epoch 8/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3989 - accuracy: 0.8546 - val_loss: 0.2943 - val_accuracy: 0.8405\n",
            "Epoch 9/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3981 - accuracy: 0.8546 - val_loss: 0.2860 - val_accuracy: 0.8405\n",
            "Epoch 10/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 0.3975 - accuracy: 0.8546 - val_loss: 0.2862 - val_accuracy: 0.8405\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd18bcac10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 25\n",
        "\n",
        "# models = [None for i in range(EPOCHS+1)]\n",
        "# optimizers = [None for i in range(EPOCHS+1)]\n",
        "cur = 20\n",
        "for e in range(cur, EPOCHS):\n",
        "    model = build_embedding_bilstm_crf_model(VOCAB_SIZE, 32, 64, 2)\n",
        "    optimizer = tf.keras.optimizers.Adam(0.02)\n",
        "\n",
        "    for epoch in range(e):\n",
        "      # Reset the metrics at the start of the next epoch\n",
        "      train_loss.reset_states()\n",
        "\n",
        "      for x, y in train_dataset:\n",
        "          train_step(x, y)\n",
        "\n",
        "      print(f\"Epoch {epoch + 1}, \" f\"Loss: {train_loss.result()}\")\n",
        "    \n",
        "      acc = 0\n",
        "      counter = 0\n",
        "      for i, row in tqdm(xxxtest.iterrows(), total=xxxtest.shape[0]):\n",
        "        tx = xxtest.loc[i]\n",
        "        ty = yytest.loc[i]\n",
        "        preprocessed_inputs = preprecess_tokens(tx.split(' '))\n",
        "        # expend the batch dim\n",
        "        inputs = tf.reshape(preprocessed_inputs, shape=[1, -1])\n",
        "\n",
        "        outputs, *_ = model.predict(inputs, verbose=0)\n",
        "        tot = (sum(outputs[0]) / len(outputs[0])) * 100\n",
        "        label = 1\n",
        "        if tot <= 50:\n",
        "          label = 0\n",
        "        # print(ty, label)\n",
        "        if ty == label:\n",
        "          acc += 1\n",
        "        # if counter > 100:\n",
        "        #   break\n",
        "        counter += 1\n",
        "      acc /= len(xxtest)\n",
        "      print('\\n', acc)\n",
        "      cur += 1"
      ],
      "metadata": {
        "id": "-cnNc7s8lgSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "\n",
        "    for x, y in train_dataset:\n",
        "        train_step(x, y)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, \" f\"Loss: {train_loss.result()}\")\n"
      ],
      "metadata": {
        "id": "q9DOvA1NnQ9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "acc = 0\n",
        "for i, row in tqdm(xxxtest.iterrows(), total=xxxtest.shape[0]):\n",
        "  tx = xxtest.loc[i]\n",
        "  ty = yytest.loc[i]\n",
        "  preprocessed_inputs = preprecess_tokens(tx.split(' '))\n",
        "  # expend the batch dim\n",
        "  inputs = tf.reshape(preprocessed_inputs, shape=[1, -1])\n",
        "\n",
        "  outputs, *_ = model.predict(inputs, verbose=0)\n",
        "  tot = (sum(outputs[0]) / len(outputs[0])) * 100\n",
        "  label = 1\n",
        "  if tot <= 50:\n",
        "    label = 0\n",
        "  # print(ty, label)\n",
        "  if ty == label:\n",
        "    acc += 1\n",
        "acc /= len(xxtest)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "Nv94sOIRnUpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo1 = tf.keras.models.load_model('/content/fm.h5')\n",
        "\n",
        "mo1.predict(np.array([[0,0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4IoZAUce54Z",
        "outputId": "a0bf8146-5851-4ead-9f4b-f50506a380d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7681172]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1LJFGfRfDuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}