{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptions:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib tqdm tensorflow torch torchvision torchaudio sklearn torchcrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:21.153443Z",
     "iopub.status.busy": "2023-03-12T13:42:21.153137Z",
     "iopub.status.idle": "2023-03-12T13:42:25.571761Z",
     "shell.execute_reply": "2023-03-12T13:42:25.570685Z",
     "shell.execute_reply.started": "2023-03-12T13:42:21.153416Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Input, Embedding, Dropout, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchcrf import CRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:25.574003Z",
     "iopub.status.busy": "2023-03-12T13:42:25.573378Z",
     "iopub.status.idle": "2023-03-12T13:42:25.675899Z",
     "shell.execute_reply": "2023-03-12T13:42:25.675210Z",
     "shell.execute_reply.started": "2023-03-12T13:42:25.573974Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/cleaned_v1/cleaned1.csv')\n",
    "\n",
    "df.loc[df['truth_value'] == 'tom_ruling_pof', 'truth_value'] = 'meter-false'\n",
    "df.loc[df['truth_value'] == 'meter-half-true', 'truth_value'] = 'meter-true'\n",
    "df.loc[df['truth_value'] == 'meter-mostly-true', 'truth_value'] = 'meter-true'\n",
    "df.loc[df['truth_value'] == 'meter-mostly-false', 'truth_value'] = 'meter-false'\n",
    "df = df.dropna(subset=['claim'])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['truth_value'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:25.677673Z",
     "iopub.status.busy": "2023-03-12T13:42:25.677142Z",
     "iopub.status.idle": "2023-03-12T13:42:25.683932Z",
     "shell.execute_reply": "2023-03-12T13:42:25.683159Z",
     "shell.execute_reply.started": "2023-03-12T13:42:25.677647Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "cdf = df.copy()\n",
    "cdf['truth_value'] = le.fit_transform(cdf['truth_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:25.686833Z",
     "iopub.status.busy": "2023-03-12T13:42:25.686833Z",
     "iopub.status.idle": "2023-03-12T13:42:25.912583Z",
     "shell.execute_reply": "2023-03-12T13:42:25.911851Z",
     "shell.execute_reply.started": "2023-03-12T13:42:25.686833Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemm_text(text):\n",
    "    return ' '.join([stemmer.stem(w) for w in text.split(' ')])\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in text.split(' ')])\n",
    "\n",
    "T = cdf['claim'].str.split(' \\n\\n---\\n\\n').str[0]\n",
    "T = T.str.replace('-',' ').str.replace('[^\\w\\s]','').str.replace('\\n',' ').str.lower()\n",
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:25.914189Z",
     "iopub.status.busy": "2023-03-12T13:42:25.913756Z",
     "iopub.status.idle": "2023-03-12T13:42:26.173171Z",
     "shell.execute_reply": "2023-03-12T13:42:26.172557Z",
     "shell.execute_reply.started": "2023-03-12T13:42:25.914163Z"
    }
   },
   "outputs": [],
   "source": [
    "T = T.apply(lambda x: ' '.join([y for y in x.split() if not y.isdigit()]))\n",
    "T = T.apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))\n",
    "cdf['claim'] = T\n",
    "cdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:26.175346Z",
     "iopub.status.busy": "2023-03-12T13:42:26.174802Z",
     "iopub.status.idle": "2023-03-12T13:42:27.926082Z",
     "shell.execute_reply": "2023-03-12T13:42:27.925257Z",
     "shell.execute_reply.started": "2023-03-12T13:42:26.175310Z"
    }
   },
   "outputs": [],
   "source": [
    "X = cdf['claim']\n",
    "y = cdf['truth_value']\n",
    "\n",
    "X = X.apply(lambda w: lemmatize_text(w))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:27.927547Z",
     "iopub.status.busy": "2023-03-12T13:42:27.927161Z",
     "iopub.status.idle": "2023-03-12T13:42:27.941307Z",
     "shell.execute_reply": "2023-03-12T13:42:27.940596Z",
     "shell.execute_reply.started": "2023-03-12T13:42:27.927522Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:42:27.942894Z",
     "iopub.status.busy": "2023-03-12T13:42:27.942413Z",
     "iopub.status.idle": "2023-03-12T13:42:30.277744Z",
     "shell.execute_reply": "2023-03-12T13:42:30.276976Z",
     "shell.execute_reply.started": "2023-03-12T13:42:27.942847Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizeAndGenerateSequences(X, y):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Maximum number of characters in a sentence = 44\n",
    "    tk = text.Tokenizer(num_words=1000)\n",
    "    tk.fit_on_texts(xtrain)\n",
    "    tokenized_train = tk.texts_to_sequences(xtrain)\n",
    "    X_train = torch.tensor(sequence.pad_sequences(tokenized_train, maxlen=60)).to(device)\n",
    "    tokenized_test = tk.texts_to_sequences(xtest)\n",
    "    X_test = torch.tensor(sequence.pad_sequences(tokenized_test, maxlen=60)).to(device)\n",
    "\n",
    "    # Convert labels to tensors\n",
    "    y_train = torch.tensor(ytrain.values).float().to(device)\n",
    "    y_test = torch.tensor(ytest.values).float().to(device)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = tokenizeAndGenerateSequences(cdf['claim'], cdf['truth_value'])\n",
    "X_train, y_train, X_test, y_test = tokenizeAndGenerateSequences(X, y)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T13:47:55.113904Z",
     "iopub.status.busy": "2023-03-12T13:47:55.113575Z",
     "iopub.status.idle": "2023-03-12T13:47:55.169294Z",
     "shell.execute_reply": "2023-03-12T13:47:55.168222Z",
     "shell.execute_reply.started": "2023-03-12T13:47:55.113878Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, num_words, embed_size, hidden_size, output_size, dropout_rate):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_words, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.bilstm1 = nn.LSTM(embed_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.bilstm2 = nn.LSTM(hidden_size * 2, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.crf = CRF(2, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x, _ = self.bilstm1(x)\n",
    "        x, _ = self.bilstm2(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.crf(x, )\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Train the model\n",
    "te = 50\n",
    "acc = []\n",
    "tracc = []\n",
    "for e in range(1, te+1):\n",
    "    ctracc = 0\n",
    "    model = BiLSTM(num_words=1000, embed_size=60, hidden_size=64, output_size=2, dropout_rate=0.2).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(e):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train.to(device))\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(X_train.to(device))\n",
    "            predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n",
    "        train_accuracy = metrics.accuracy_score(y_train.to('cpu'), predictions)\n",
    "        ctracc += train_accuracy\n",
    "\n",
    "    ctracc /= e\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test)\n",
    "        predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n",
    "\n",
    "    print(f\"Total Epochs: {e}, Train Accuracy: {ctracc} Test Accuracy: {metrics.accuracy_score(y_test.to('cpu'), predictions)}\")\n",
    "    acc.append(metrics.accuracy_score(y_test.to('cpu'), predictions))\n",
    "    tracc.append(ctracc)\n",
    "#     break\n",
    "print('Max acc -', max(acc), ' with epochs -', acc.index(max(acc)))\n",
    "# plt.plot([i for i in range(1, 51)], acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a897ce92e780bd0a113d3cbc4b391fa94b12f7aeaa7a9fdb40b859980fef9d59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
