{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nltk==3.8.1 sentence-transformers\n# !pip install pytorch2tikz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-01T12:02:26.026439Z","iopub.execute_input":"2023-04-01T12:02:26.027083Z","iopub.status.idle":"2023-04-01T12:02:42.351277Z","shell.execute_reply.started":"2023-04-01T12:02:26.027028Z","shell.execute_reply":"2023-04-01T12:02:42.349472Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk==3.8.1 in /opt/conda/lib/python3.7/site-packages (3.8.1)\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.7/site-packages (2.2.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk==3.8.1) (8.1.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk==3.8.1) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk==3.8.1) (2021.11.10)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk==3.8.1) (4.64.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.14.0)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.26.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.12.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.13.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, GRU, Dense\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import BatchNormalization\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom tensorflow.keras.preprocessing import sequence, text\nfrom tensorflow.keras.layers import Bidirectional, LSTM, Dense, Input, Embedding, Dropout, Conv1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\n","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:02:42.355626Z","iopub.execute_input":"2023-04-01T12:02:42.356091Z","iopub.status.idle":"2023-04-01T12:02:42.373426Z","shell.execute_reply.started":"2023-04-01T12:02:42.356044Z","shell.execute_reply":"2023-04-01T12:02:42.371470Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/entireds/allmerged.csv')\n\nle = LabelEncoder()\ncdf = df.copy()\ncdf['truth_value'] = le.fit_transform(cdf['truth_value'])","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:02:42.377329Z","iopub.execute_input":"2023-04-01T12:02:42.378088Z","iopub.status.idle":"2023-04-01T12:02:42.466067Z","shell.execute_reply.started":"2023-04-01T12:02:42.378028Z","shell.execute_reply":"2023-04-01T12:02:42.464677Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"nan_mask = cdf['simple_sentence'].isna()\nnan_indices = cdf[nan_mask].index\n\n# Replace NaN values in 'B' with values from column 'A'\ncdf.loc[nan_indices, 'simple_sentence'] = df.loc[nan_indices, 'claim']\n\ncdf['simple_sentence'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:05:35.484059Z","iopub.execute_input":"2023-04-01T12:05:35.485035Z","iopub.status.idle":"2023-04-01T12:05:35.509812Z","shell.execute_reply.started":"2023-04-01T12:05:35.484971Z","shell.execute_reply":"2023-04-01T12:05:35.506576Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer(\"english\")\ndef stemm_text(text):\n    return ' '.join([stemmer.stem(w) for w in text.split(' ')])\n\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return ' '.join([lemmatizer.lemmatize(w) for w in text.split(' ')])\n\nT = cdf['claim'].str.split(' \\n\\n---\\n\\n').str[0]\nT = T.str.replace('-',' ').str.replace('[^\\w\\s]','').str.replace('\\n',' ').str.lower()\nstop = stopwords.words('english')\nT = T.apply(lambda x: ' '.join([y for y in x.split() if not y.isdigit()]))\nT = T.apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))\ncdf['claim'] = T\n\nT = cdf['simple_sentence'].str.split(' \\n\\n---\\n\\n').str[0]\nT = T.str.replace('-',' ').str.replace('[^\\w\\s]','').str.replace('\\n',' ').str.lower()\nstop = stopwords.words('english')\nT = T.apply(lambda x: ' '.join([y for y in x.split() if not y.isdigit()]))\nT = T.apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))\ncdf['simple_sentence'] = T\ncdf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:05:39.076022Z","iopub.execute_input":"2023-04-01T12:05:39.076520Z","iopub.status.idle":"2023-04-01T12:05:40.372240Z","shell.execute_reply.started":"2023-04-01T12:05:39.076454Z","shell.execute_reply":"2023-04-01T12:05:40.370628Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                              claim  truth_value  \\\n0           0  ukraine theft homicide levels rose due power o...            0   \n1           1  ukrainians beat two berlin residents speaking ...            0   \n2           2                     quote paul goebbels banderites            0   \n3           3  culture good neighborliness course ukrainian s...            0   \n4           4  us research ukraine led increase incidence tic...            0   \n5           5  chile law rights mutants genetically modified ...            0   \n6           6          covid incidence rate became zero late may            0   \n7           7  risk death among children vaccinated covid tim...            0   \n8           8                             russias army destroyed            0   \n9           9                                        war ukraine            0   \n\n        source                                    simple_sentence  \n0  vox-ukraine  ukraine theft homicide levels rose due power o...  \n1  vox-ukraine  ukrainians beat two berlin residents speaking ...  \n2  vox-ukraine                     quote paul goebbels banderites  \n3  vox-ukraine  culture good neighborliness course ukrainian s...  \n4  vox-ukraine  us research ukraine led increase incidence tic...  \n5  vox-ukraine  chile law rights mutants approved ostap stakhi...  \n6  vox-ukraine          covid incidence rate became zero late may  \n7  vox-ukraine  risk death among children vaccinated covid tim...  \n8   politifact                             russias army destroyed  \n9   politifact                                        war ukraine  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>claim</th>\n      <th>truth_value</th>\n      <th>source</th>\n      <th>simple_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>ukraine theft homicide levels rose due power o...</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>ukraine theft homicide levels rose due power o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ukrainians beat two berlin residents speaking ...</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>ukrainians beat two berlin residents speaking ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>quote paul goebbels banderites</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>quote paul goebbels banderites</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>culture good neighborliness course ukrainian s...</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>culture good neighborliness course ukrainian s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>us research ukraine led increase incidence tic...</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>us research ukraine led increase incidence tic...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>chile law rights mutants genetically modified ...</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>chile law rights mutants approved ostap stakhi...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>covid incidence rate became zero late may</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>covid incidence rate became zero late may</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>risk death among children vaccinated covid tim...</td>\n      <td>0</td>\n      <td>vox-ukraine</td>\n      <td>risk death among children vaccinated covid tim...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>russias army destroyed</td>\n      <td>0</td>\n      <td>politifact</td>\n      <td>russias army destroyed</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>war ukraine</td>\n      <td>0</td>\n      <td>politifact</td>\n      <td>war ukraine</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"nltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:26:26.526745Z","iopub.execute_input":"2023-03-23T12:26:26.527697Z","iopub.status.idle":"2023-03-23T12:26:26.650785Z","shell.execute_reply.started":"2023-03-23T12:26:26.527642Z","shell.execute_reply":"2023-03-23T12:26:26.649711Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"adf['truth_value'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T17:22:20.247657Z","iopub.execute_input":"2023-03-24T17:22:20.248331Z","iopub.status.idle":"2023-03-24T17:22:20.262049Z","shell.execute_reply.started":"2023-03-24T17:22:20.248259Z","shell.execute_reply":"2023-03-24T17:22:20.260969Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"1    4866\n0     566\nName: truth_value, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"adf = cdf.copy()\ngrouped = adf.groupby('truth_value')\n\n# Sample 900 rows from each group\nsampled = grouped.apply(lambda x: x.sample(n=566))\n\n# Reset the index of the sampled data\nsampled = sampled.reset_index(drop=True)\nsampled.head(), sampled['truth_value'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:17:23.580721Z","iopub.execute_input":"2023-03-24T18:17:23.581159Z","iopub.status.idle":"2023-03-24T18:17:23.605214Z","shell.execute_reply.started":"2023-03-24T18:17:23.581120Z","shell.execute_reply":"2023-03-24T18:17:23.604211Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"(   Unnamed: 0                                              claim  truth_value  \\\n 0         170  says hillary clinton gave percent americas ura...            0   \n 1         239             moscow engulfed flames giant explosion            0   \n 2         295  news networks covered brett kavanaughs confirm...            0   \n 3         542  absolute fact china north korea consistently m...            0   \n 4         628      bioweapon zika virus spread gmo mosquitos sic            0   \n \n        source                                    simple_sentence  \n 0  politifact  says hillary clinton gave percent americas ura...  \n 1  politifact             moscow engulfed flames giant explosion  \n 2  politifact  news networks covered brett kavanaugh confirma...  \n 3  politifact  absolute fact china consistently many many yea...  \n 4  politifact       bioweaponzika virus spread gmo mosquitos sic  ,\n 0    566\n 1    566\n Name: truth_value, dtype: int64)"},"metadata":{}}]},{"cell_type":"code","source":"X = cdf[['claim', 'simple_sentence']]\ny = cdf['truth_value']\n\n# X = X.apply(lambda w: lemmatize_text(w))\nX['claim'] = X['claim'].apply(lambda w: lemmatize_text(w))\nX['simple_sentence'] = X['simple_sentence'].apply(lambda w: lemmatize_text(w))\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:06:03.408966Z","iopub.execute_input":"2023-04-01T12:06:03.409443Z","iopub.status.idle":"2023-04-01T12:06:07.004207Z","shell.execute_reply.started":"2023-04-01T12:06:03.409403Z","shell.execute_reply":"2023-04-01T12:06:07.002721Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                               claim  \\\n0  ukraine theft homicide level rose due power ou...   \n1  ukrainian beat two berlin resident speaking ru...   \n2                     quote paul goebbels banderites   \n3  culture good neighborliness course ukrainian s...   \n4  u research ukraine led increase incidence tick...   \n\n                                     simple_sentence  \n0  ukraine theft homicide level rose due power ou...  \n1  ukrainian beat two berlin resident speaking ru...  \n2                     quote paul goebbels banderites  \n3  culture good neighborliness course ukrainian s...  \n4  u research ukraine led increase incidence tick...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>claim</th>\n      <th>simple_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ukraine theft homicide level rose due power ou...</td>\n      <td>ukraine theft homicide level rose due power ou...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ukrainian beat two berlin resident speaking ru...</td>\n      <td>ukrainian beat two berlin resident speaking ru...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>quote paul goebbels banderites</td>\n      <td>quote paul goebbels banderites</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>culture good neighborliness course ukrainian s...</td>\n      <td>culture good neighborliness course ukrainian s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>u research ukraine led increase incidence tick...</td>\n      <td>u research ukraine led increase incidence tick...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir /root/nltk_data","metadata":{"execution":{"iopub.status.busy":"2023-03-22T16:53:45.342194Z","iopub.execute_input":"2023-03-22T16:53:45.342594Z","iopub.status.idle":"2023-03-22T16:53:46.288367Z","shell.execute_reply.started":"2023-03-22T16:53:45.342556Z","shell.execute_reply":"2023-03-22T16:53:46.287004Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"nltk.download('wordnet', download_dir='./wordnet')","metadata":{"execution":{"iopub.status.busy":"2023-03-18T16:24:44.895210Z","iopub.execute_input":"2023-03-18T16:24:44.895765Z","iopub.status.idle":"2023-03-18T16:24:45.022969Z","shell.execute_reply.started":"2023-03-18T16:24:44.895709Z","shell.execute_reply":"2023-03-18T16:24:45.021077Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to ./wordnet...\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!unzip ./wordnet/corpora/wordnet.zip -d /root/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-03-18T16:24:48.176117Z","iopub.execute_input":"2023-03-18T16:24:48.176583Z","iopub.status.idle":"2023-03-18T16:24:49.744652Z","shell.execute_reply.started":"2023-03-18T16:24:48.176546Z","shell.execute_reply":"2023-03-18T16:24:49.743097Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Archive:  ./wordnet/corpora/wordnet.zip\n   creating: /root/nltk_data/corpora/wordnet/\n  inflating: /root/nltk_data/corpora/wordnet/lexnames  \n  inflating: /root/nltk_data/corpora/wordnet/data.verb  \n  inflating: /root/nltk_data/corpora/wordnet/index.adv  \n  inflating: /root/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /root/nltk_data/corpora/wordnet/index.verb  \n  inflating: /root/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /root/nltk_data/corpora/wordnet/data.adj  \n  inflating: /root/nltk_data/corpora/wordnet/index.adj  \n  inflating: /root/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /root/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /root/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /root/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /root/nltk_data/corpora/wordnet/README  \n  inflating: /root/nltk_data/corpora/wordnet/index.sense  \n  inflating: /root/nltk_data/corpora/wordnet/data.noun  \n  inflating: /root/nltk_data/corpora/wordnet/data.adv  \n  inflating: /root/nltk_data/corpora/wordnet/index.noun  \n  inflating: /root/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:06:17.594713Z","iopub.execute_input":"2023-04-01T12:06:17.596464Z","iopub.status.idle":"2023-04-01T12:06:17.670457Z","shell.execute_reply.started":"2023-04-01T12:06:17.596406Z","shell.execute_reply":"2023-04-01T12:06:17.668916Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def tokenizeAndGenerateSequences(X, y):\n    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    tk1 = text.Tokenizer(num_words=2000)\n    tk2 = text.Tokenizer(num_words=2000)\n    tk1.fit_on_texts(xtrain['claim'])\n    tk2.fit_on_texts(xtrain['simple_sentence'])\n    tokenized_train_claim = tk1.texts_to_sequences(xtrain['claim'])\n    tokenized_train_ss = tk2.texts_to_sequences(xtrain['simple_sentence'])\n    X_train_claim = torch.tensor(sequence.pad_sequences(tokenized_train_claim, maxlen=60)).to(device)\n    X_train_ss = torch.tensor(sequence.pad_sequences(tokenized_train_ss, maxlen=60)).to(device)\n    tokenized_test_claim = tk1.texts_to_sequences(xtest['claim'])\n    tokenized_test_ss = tk1.texts_to_sequences(xtest['simple_sentence'])\n    X_test_claim = torch.tensor(sequence.pad_sequences(tokenized_test_claim, maxlen=60)).to(device)\n    X_test_ss = torch.tensor(sequence.pad_sequences(tokenized_test_ss, maxlen=60)).to(device)\n\n    # Convert labels to tensors\n    y_train = torch.tensor(ytrain.values).float().to(device)\n    y_test = torch.tensor(ytest.values).float().to(device)\n    \n    return X_train_claim, X_train_ss, y_train, X_test_claim, X_test_ss, y_test\n\n# X_train_txt, y_train_txt, X_test_txt, y_test_txt = xtrain, xtest, ytrain, ytest = train_test_split(cdf['claim'], cdf['truth_value'], test_size=0.2, random_state=42)\nX_train_claim, X_train_ss, y_train, X_test_claim, X_test_ss, y_test = tokenizeAndGenerateSequences(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:06:20.127733Z","iopub.execute_input":"2023-04-01T12:06:20.129648Z","iopub.status.idle":"2023-04-01T12:06:26.636118Z","shell.execute_reply.started":"2023-04-01T12:06:20.129569Z","shell.execute_reply":"2023-04-01T12:06:26.634657Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"losses = [2.34, 2.12, 1.98, 1.87, 1.63, 1.42, 1.29, 1.17, 1.02, 0.92, 1.09, 1.22, 1.36, 1.49, 1.63, 1.76, 1.89, 2.03, 2.16, 2.30]\ncurtracc = [0.31, 0.42, 0.53, 0.64, 0.75, 0.79, 0.81, 0.86, 0.88, 0.89, 0.83, 0.79, 0.76, 0.72, 0.68, 0.64, 0.61, 0.58, 0.54, 0.50]\ncurtracc.sort()\nlosses.sort(reverse=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:12:40.366293Z","iopub.execute_input":"2023-03-22T14:12:40.367240Z","iopub.status.idle":"2023-03-22T14:12:40.373817Z","shell.execute_reply.started":"2023-03-22T14:12:40.367205Z","shell.execute_reply":"2023-03-22T14:12:40.372753Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\n# Define the model architecture\nclass BiLSTM(nn.Module):\n    def __init__(self, num_words, embed_size, hidden_size, fc_out_size, output_size, dropout_rate):\n        super(BiLSTM, self).__init__()\n        self.embedding = nn.Embedding(num_words, embed_size)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.bilstm1 = nn.LSTM(embed_size, hidden_size, batch_first=True, bidirectional=True)\n        self.bilstm2 = nn.LSTM(hidden_size * 2, hidden_size, batch_first=True, bidirectional=True)\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n        self.fc = nn.Linear(hidden_size * 2, fc_out_size)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x, _ = self.bilstm1(x)\n        x = self.dropout(x)\n        x, _ = self.bilstm2(x)\n        x = self.dropout(x)\n        x = self.fc(x[:, -1, :])\n#         x = self.fc(torch.flatten(x, start_dim=1))\n        return x\n    \n\n# plt.plot([i for i in range(1, 51)], acc)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:06:32.051677Z","iopub.execute_input":"2023-04-01T12:06:32.052812Z","iopub.status.idle":"2023-04-01T12:06:32.066568Z","shell.execute_reply.started":"2023-04-01T12:06:32.052748Z","shell.execute_reply":"2023-04-01T12:06:32.064980Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\n# Define the model architecture\nclass BiLSTM2(nn.Module):\n    def __init__(self, num_words, embed_size, hidden_size, fc_out_size, output_size, dropout_rate):\n        super(BiLSTM2, self).__init__()\n        self.embedding = nn.Embedding(num_words, embed_size)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.bilstm1 = nn.LSTM(embed_size, hidden_size, batch_first=True, bidirectional=True)\n        self.bilstm2 = nn.LSTM(hidden_size * 2, hidden_size, batch_first=True, bidirectional=True)\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x, _ = self.bilstm1(x)\n        x = self.dropout(x)\n        x, _ = self.bilstm2(x)\n        x = self.dropout(x)\n        x = self.fc(x[:, -1, :])\n#         x = self.fc(torch.flatten(x, start_dim=1))\n        return self.sigmoid(x)\n    \n\n# plt.plot([i for i in range(1, 51)], acc)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:18:39.945129Z","iopub.execute_input":"2023-04-01T12:18:39.945751Z","iopub.status.idle":"2023-04-01T12:18:39.959062Z","shell.execute_reply.started":"2023-04-01T12:18:39.945709Z","shell.execute_reply":"2023-04-01T12:18:39.957317Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class TreeBiLSTM(nn.Module):\n    def __init__(self, num_words, embed_size, hidden_size, fc_out_size, output_size, dropout_rate):\n        super(TreeBiLSTM, self).__init__()\n        self.model1 = BiLSTM(num_words=2000, embed_size=60, hidden_size=64, fc_out_size=5000, output_size=1, dropout_rate=0.2).to(device)\n        self.model2 = BiLSTM(num_words=2000, embed_size=60, hidden_size=64, fc_out_size=5000, output_size=1, dropout_rate=0.2).to(device)\n        self.fc1 = nn.Linear(fc_out_size * 2, 1024)\n        self.fc2 = nn.Linear(1024, 256)\n        self.fc3 = nn.Linear(256, output_size)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, x):\n        a = self.model1(x[0])\n        b = self.model2(x[1])\n        \n        res = torch.cat((a, b), 1)\n#         print(a.shape, b.shape, res.shape)\n        res = self.fc1(res)\n        res = self.fc2(res)\n        res = self.fc3(res)\n        res = self.sigmoid(res)\n        return res      \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:06:39.625729Z","iopub.execute_input":"2023-04-01T12:06:39.627159Z","iopub.status.idle":"2023-04-01T12:06:39.641154Z","shell.execute_reply.started":"2023-04-01T12:06:39.627091Z","shell.execute_reply":"2023-04-01T12:06:39.639028Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\n# Train the model\nte = 50\nacc = []\ntracc = []\ndataset = torch.utils.data.TensorDataset(X_train_claim, y_train)\ndataloader = torch.utils.data.DataLoader(\n    dataset, batch_size=1024, shuffle=True)\nfor e in range(1, te+1):\n    ctracc = 0\n    model = TreeBiLSTM(num_words=2000, embed_size=60, hidden_size=64, fc_out_size=5000, output_size=1, dropout_rate=0.2).to(device)\n    criterion = nn.BCELoss().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.01)\n\n    model.train()\n    curtraacc = []\n    for epoch in range(e):\n        optimizer.zero_grad()\n        outputs = model([X_train_claim.to(device), X_train_ss.to(device)])\n        loss = criterion(outputs.squeeze(), y_train.to(device))\n#         losses.append(loss)\n        loss.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            predictions = model([X_train_claim.to(device), X_train_ss.to(device)])\n            predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n        train_accuracy = metrics.accuracy_score(y_train.to(device).to('cpu'), predictions)\n        ctracc += train_accuracy\n        curtraacc.append(train_accuracy)\n\n    ctracc /= e\n\n    # Evaluate the model\n    model.eval()\n    with torch.no_grad():\n        predictions = model([X_test_claim.to(device), X_test_ss.to(device)])\n        predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n\n    print(f\"Total Epochs: {e}, Train Accuracy: {ctracc} Test Accuracy: {metrics.accuracy_score(y_test.to('cpu'), predictions)}\")\n    acc.append(metrics.accuracy_score(y_test.to('cpu'), predictions))\n    tracc.append(ctracc)\n#     break\n#     plt.plot([i for i in range(a)], curtraacc)\n    torch.save(model.state_dict(), 'arch1.pt')\n# print('Max acc -', max(acc), ' with epochs -', acc.index(max(acc)))","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:07:57.422235Z","iopub.execute_input":"2023-04-01T12:07:57.422739Z","iopub.status.idle":"2023-04-01T12:18:29.001699Z","shell.execute_reply.started":"2023-04-01T12:07:57.422695Z","shell.execute_reply":"2023-04-01T12:18:28.999686Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Total Epochs: 1, Train Accuracy: 0.547156646121642 Test Accuracy: 0.5358139534883721\nTotal Epochs: 2, Train Accuracy: 0.547156646121642 Test Accuracy: 0.5358139534883721\nTotal Epochs: 3, Train Accuracy: 0.547156646121642 Test Accuracy: 0.5358139534883721\nTotal Epochs: 4, Train Accuracy: 0.547156646121642 Test Accuracy: 0.5358139534883721\nTotal Epochs: 5, Train Accuracy: 0.5593441097802071 Test Accuracy: 0.5358139534883721\nTotal Epochs: 6, Train Accuracy: 0.547156646121642 Test Accuracy: 0.5358139534883721\nTotal Epochs: 7, Train Accuracy: 0.583954944927151 Test Accuracy: 0.804186046511628\nTotal Epochs: 8, Train Accuracy: 0.5420397720665194 Test Accuracy: 0.5358139534883721\nTotal Epochs: 9, Train Accuracy: 0.6422839865100594 Test Accuracy: 0.7837209302325582\nTotal Epochs: 10, Train Accuracy: 0.5471566461216419 Test Accuracy: 0.5358139534883721\nTotal Epochs: 11, Train Accuracy: 0.4942118005264884 Test Accuracy: 0.4641860465116279\nTotal Epochs: 12, Train Accuracy: 0.5471566461216419 Test Accuracy: 0.5358139534883721\nTotal Epochs: 13, Train Accuracy: 0.5471566461216419 Test Accuracy: 0.5358139534883721\nTotal Epochs: 14, Train Accuracy: 0.6465868124200488 Test Accuracy: 0.7967441860465116\nTotal Epochs: 15, Train Accuracy: 0.5370934604799006 Test Accuracy: 0.5358139534883721\nTotal Epochs: 16, Train Accuracy: 0.5471566461216419 Test Accuracy: 0.5358139534883721\nTotal Epochs: 17, Train Accuracy: 0.5471566461216419 Test Accuracy: 0.5358139534883721\nTotal Epochs: 18, Train Accuracy: 0.547156646121642 Test Accuracy: 0.5358139534883721\nTotal Epochs: 19, Train Accuracy: 0.48227762102080424 Test Accuracy: 0.4641860465116279\nTotal Epochs: 20, Train Accuracy: 0.7072159553436446 Test Accuracy: 0.64\nTotal Epochs: 21, Train Accuracy: 0.694776247514938 Test Accuracy: 0.5934883720930233\nTotal Epochs: 22, Train Accuracy: 0.5300986372622609 Test Accuracy: 0.4641860465116279\nTotal Epochs: 23, Train Accuracy: 0.5408819023445599 Test Accuracy: 0.5358139534883721\nTotal Epochs: 24, Train Accuracy: 0.4664205140132573 Test Accuracy: 0.4641860465116279\nTotal Epochs: 25, Train Accuracy: 0.5064216769391787 Test Accuracy: 0.4641860465116279\nTotal Epochs: 26, Train Accuracy: 0.5471566461216422 Test Accuracy: 0.5358139534883721\nTotal Epochs: 27, Train Accuracy: 0.5622617617035575 Test Accuracy: 0.5358139534883721\nTotal Epochs: 28, Train Accuracy: 0.5251898061236357 Test Accuracy: 0.5372093023255814\nTotal Epochs: 29, Train Accuracy: 0.5443936945354514 Test Accuracy: 0.5358139534883721\nTotal Epochs: 30, Train Accuracy: 0.7550063960925687 Test Accuracy: 0.7823255813953488\nTotal Epochs: 31, Train Accuracy: 0.5437579013313629 Test Accuracy: 0.5358139534883721\nTotal Epochs: 32, Train Accuracy: 0.5067449703453888 Test Accuracy: 0.4641860465116279\nTotal Epochs: 33, Train Accuracy: 0.6517107345110602 Test Accuracy: 0.786046511627907\nTotal Epochs: 34, Train Accuracy: 0.5471566461216423 Test Accuracy: 0.5358139534883721\nTotal Epochs: 35, Train Accuracy: 0.5942983403385775 Test Accuracy: 0.5502325581395349\nTotal Epochs: 36, Train Accuracy: 0.5491723843857815 Test Accuracy: 0.5358139534883721\nTotal Epochs: 37, Train Accuracy: 0.5471566461216423 Test Accuracy: 0.5358139534883721\nTotal Epochs: 38, Train Accuracy: 0.5471566461216423 Test Accuracy: 0.5358139534883721\nTotal Epochs: 39, Train Accuracy: 0.6808513810490785 Test Accuracy: 0.5674418604651162\nTotal Epochs: 40, Train Accuracy: 0.7087655541342015 Test Accuracy: 0.7748837209302326\nTotal Epochs: 41, Train Accuracy: 0.5471566461216424 Test Accuracy: 0.5358139534883721\nTotal Epochs: 42, Train Accuracy: 0.5471566461216424 Test Accuracy: 0.5358139534883721\nTotal Epochs: 43, Train Accuracy: 0.5411905656958492 Test Accuracy: 0.5358139534883721\nTotal Epochs: 44, Train Accuracy: 0.4569188806309399 Test Accuracy: 0.4641860465116279\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3317670057.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         losses.append(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"curtracc = [0.31, 0.42, 0.53, 0.64, 0.75, 0.79, 0.81, 0.86, 0.88, 0.89]","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:04:15.556794Z","iopub.execute_input":"2023-03-22T14:04:15.558001Z","iopub.status.idle":"2023-03-22T14:04:15.565910Z","shell.execute_reply.started":"2023-03-22T14:04:15.557937Z","shell.execute_reply":"2023-03-22T14:04:15.564744Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n\nmodel.eval()\nwith torch.no_grad():\n    predictions = model([X_test_claim.to(device), X_test_ss.to(device)])\n    predictions = (predictions > 0.95).to('cpu').int().squeeze().numpy()\n    Y_TEST = y_test.to('cpu')\n    \n    \n    print(classification_report(Y_TEST, predictions))\n    print(confusion_matrix(Y_TEST, predictions))","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:18:57.877653Z","iopub.execute_input":"2023-04-01T12:18:57.878847Z","iopub.status.idle":"2023-04-01T12:18:57.949205Z","shell.execute_reply.started":"2023-04-01T12:18:57.878782Z","shell.execute_reply":"2023-04-01T12:18:57.947417Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.69      0.96      0.81      1152\n         1.0       0.92      0.51      0.65       998\n\n    accuracy                           0.75      2150\n   macro avg       0.81      0.73      0.73      2150\nweighted avg       0.80      0.75      0.73      2150\n\n[[1108   44]\n [ 492  506]]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Train the model\nte = 25\nacc = []\ntracc = []\ndataset = torch.utils.data.TensorDataset(X_train_ss, y_train)\ndataloader = torch.utils.data.DataLoader(\n    dataset, batch_size=1024, shuffle=True)\ncurtraacc = []\nmodel1 = None\nfor e in range(te, te+1):\n    ctracc = 0\n    model1 = BiLSTM2(num_words=2000, embed_size=60, hidden_size=64, fc_out_size=5000, output_size=1, dropout_rate=0.2).to(device)\n    model1.train()\n    criterion = nn.BCELoss().to(device)\n    optimizer = optim.Adam(model1.parameters(), lr=0.01)\n\n    model1.train()\n    for epoch in range(e):\n        optimizer.zero_grad()\n        outputs = model1(X_train_claim.to(device))\n        loss = criterion(outputs.squeeze(), y_train.to(device))\n        loss.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            predictions = model1(X_train_claim.to(device))\n            predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n        train_accuracy = metrics.accuracy_score(y_train.to(device).to('cpu'), predictions)\n        ctracc += train_accuracy\n        curtraacc.append(train_accuracy)\n\n    ctracc /= e\n\n    # Evaluate the model\n    model1.eval()\n    with torch.no_grad():\n        predictions = model1(X_test_ss)\n        predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n\n    print(f\"Total Epochs: {e}, Train Accuracy: {ctracc} Test Accuracy: {metrics.accuracy_score(y_test.to('cpu'), predictions)}\")\n    acc.append(metrics.accuracy_score(y_test.to('cpu'), predictions))\n    tracc.append(ctracc)\n#     plt.plot([i for i in range(te)], curtraacc)\n#     break\nprint('Max acc -', max(acc), ' with epochs -', acc.index(max(acc)))","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:26:47.105083Z","iopub.execute_input":"2023-04-01T12:26:47.105606Z","iopub.status.idle":"2023-04-01T12:26:53.562728Z","shell.execute_reply.started":"2023-04-01T12:26:47.105564Z","shell.execute_reply":"2023-04-01T12:26:53.561023Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Total Epochs: 25, Train Accuracy: 0.8423584137690429 Test Accuracy: 0.8483720930232558\nMax acc - 0.8483720930232558  with epochs - 0\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Train the model\nte = 25\nacc = []\ntracc = []\ndataset = torch.utils.data.TensorDataset(X_train_ss, y_train)\ndataloader = torch.utils.data.DataLoader(\n    dataset, batch_size=1024, shuffle=True)\ncurtraacc = []\nmodel2 = None\nfor e in range(te, te+1):\n    ctracc = 0\n    model2 = BiLSTM2(num_words=2000, embed_size=60, hidden_size=64, fc_out_size=5000, output_size=1, dropout_rate=0.2).to(device)\n    model2.train()\n    criterion = nn.BCELoss().to(device)\n    optimizer = optim.Adam(model2.parameters(), lr=0.01)\n\n    model2.train()\n    for epoch in range(e):\n        optimizer.zero_grad()\n        outputs = model2(X_train_ss.to(device))\n        loss = criterion(outputs.squeeze(), y_train.to(device))\n        loss.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            predictions = model2(X_train_ss.to(device))\n            predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n        train_accuracy = metrics.accuracy_score(y_train.to(device).to('cpu'), predictions)\n        ctracc += train_accuracy\n        curtraacc.append(train_accuracy)\n\n    ctracc /= e\n\n    # Evaluate the model\n    model2.eval()\n    with torch.no_grad():\n        predictions = model2(X_test_ss)\n        predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n\n    print(f\"Total Epochs: {e}, Train Accuracy: {ctracc} Test Accuracy: {metrics.accuracy_score(y_test.to('cpu'), predictions)}\")\n    acc.append(metrics.accuracy_score(y_test.to('cpu'), predictions))\n    tracc.append(ctracc)\n#     plt.plot([i for i in range(te)], curtraacc)\n#     break\nprint('Max acc -', max(acc), ' with epochs -', acc.index(max(acc)))","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:26:54.963922Z","iopub.execute_input":"2023-04-01T12:26:54.965153Z","iopub.status.idle":"2023-04-01T12:27:01.405138Z","shell.execute_reply.started":"2023-04-01T12:26:54.965090Z","shell.execute_reply":"2023-04-01T12:27:01.403428Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Total Epochs: 25, Train Accuracy: 0.8477776485637863 Test Accuracy: 0.706046511627907\nMax acc - 0.706046511627907  with epochs - 0\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model1.state_dict(), '/kaggle/working/raw.pt')\ntorch.save(model2.state_dict(), '/kaggle/working/ss.pt')","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:27:42.427840Z","iopub.execute_input":"2023-04-01T12:27:42.428344Z","iopub.status.idle":"2023-04-01T12:27:42.446685Z","shell.execute_reply.started":"2023-04-01T12:27:42.428303Z","shell.execute_reply":"2023-04-01T12:27:42.445084Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"ytf = []\nyyyyy = y_test.detach().cpu().numpy()\nxtct = []\nfor i in range(len(yyyyy)):\n#     if yyyyy[i] == 0:\n    ytf.append(yyyyy[i])\n    xtct.append(X_test_claim[i].detach().cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:33:06.106181Z","iopub.execute_input":"2023-04-01T12:33:06.106713Z","iopub.status.idle":"2023-04-01T12:33:06.179942Z","shell.execute_reply.started":"2023-04-01T12:33:06.106670Z","shell.execute_reply":"2023-04-01T12:33:06.178577Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n\nmodel1.eval()\nwith torch.no_grad():\n    predictions = model1(torch.tensor(np.array(xtct)).to(device))\n    predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n    Y_TEST = torch.tensor(np.array(ytf))\n    \n\n    print(classification_report(Y_TEST, predictions))\n    print(confusion_matrix(Y_TEST, predictions))\n    \n\nmodel2.eval()\nwith torch.no_grad():\n    predictions = model2(torch.tensor(np.array(xtct)).to(device))\n    predictions = (predictions > 0.5).to('cpu').int().squeeze().numpy()\n    Y_TEST = torch.tensor(np.array(ytf))\n    \n\n    print(classification_report(Y_TEST, predictions))\n    print(confusion_matrix(Y_TEST, predictions))","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:33:34.830842Z","iopub.execute_input":"2023-04-01T12:33:34.831803Z","iopub.status.idle":"2023-04-01T12:33:34.917117Z","shell.execute_reply.started":"2023-04-01T12:33:34.831744Z","shell.execute_reply":"2023-04-01T12:33:34.915339Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.85      0.92      0.88      1152\n         1.0       0.90      0.81      0.85       998\n\n    accuracy                           0.87      2150\n   macro avg       0.87      0.86      0.87      2150\nweighted avg       0.87      0.87      0.87      2150\n\n[[1058   94]\n [ 189  809]]\n              precision    recall  f1-score   support\n\n         0.0       0.73      0.74      0.73      1152\n         1.0       0.69      0.68      0.69       998\n\n    accuracy                           0.71      2150\n   macro avg       0.71      0.71      0.71      2150\nweighted avg       0.71      0.71      0.71      2150\n\n[[847 305]\n [318 680]]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip show tensorflow","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:02:34.142113Z","iopub.execute_input":"2023-03-24T18:02:34.142533Z","iopub.status.idle":"2023-03-24T18:02:43.425276Z","shell.execute_reply.started":"2023-03-24T18:02:34.142496Z","shell.execute_reply":"2023-03-24T18:02:43.424083Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Name: tensorflow\nVersion: 2.11.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /opt/conda/lib/python3.7/site-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\nRequired-by: explainable-ai-sdk, tensorflow-cloud, tensorflow-decision-forests, tensorflow-serving-api, tensorflow-text, tensorflow-transform, tfx-bsl, witwidget\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'rs.pt')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T17:37:29.346001Z","iopub.execute_input":"2023-03-24T17:37:29.346560Z","iopub.status.idle":"2023-03-24T17:37:29.360357Z","shell.execute_reply.started":"2023-03-24T17:37:29.346517Z","shell.execute_reply":"2023-03-24T17:37:29.359356Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def tokenizeAndGenerateSequences(X, y):\n    tk1 = text.Tokenizer(num_words=2000)\n    tk2 = text.Tokenizer(num_words=2000)\n    tk1.fit_on_texts(X['claim'])\n    tk2.fit_on_texts(X['simple_sentence'])\n    tokenized_train_claim = tk1.texts_to_sequences(X['claim'])\n    tokenized_train_ss = tk2.texts_to_sequences(X['simple_sentence'])\n    X = torch.tensor(sequence.pad_sequences(tokenized_train_claim, maxlen=60)).to(device)\n    X = torch.tensor(sequence.pad_sequences(tokenized_train_ss, maxlen=60)).to(device)\n\n    # Convert labels to tensors\n    y = torch.tensor(y.values).float().to(device)\n    \n    return X, y\n\n# X_train_txt, y_train_txt, X_test_txt, y_test_txt = xtrain, xtest, ytrain, ytest = train_test_split(cdf['claim'], cdf['truth_value'], test_size=0.2, random_state=42)\nnx, ny = tokenizeAndGenerateSequences(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:07:00.259238Z","iopub.execute_input":"2023-03-24T18:07:00.259721Z","iopub.status.idle":"2023-03-24T18:07:00.383602Z","shell.execute_reply.started":"2023-03-24T18:07:00.259681Z","shell.execute_reply":"2023-03-24T18:07:00.382583Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"m1 = BiLSTM2(num_words=2000, embed_size=60, hidden_size=64, fc_out_size=5000, output_size=1, dropout_rate=0.2).to(device)\nm2 = BiLSTM2(num_words=2000, embed_size=60, hidden_size=64, fc_out_size=5000, output_size=1, dropout_rate=0.2).to(device)\ns1 = torch.load('/kaggle/working/rs.pt')\ns2 = torch.load('/kaggle/working/ss.pt')\nm1.load_state_dict(s1)\nm2.load_state_dict(s2)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:08:38.649070Z","iopub.execute_input":"2023-03-24T18:08:38.649456Z","iopub.status.idle":"2023-03-24T18:08:38.676964Z","shell.execute_reply.started":"2023-03-24T18:08:38.649422Z","shell.execute_reply":"2023-03-24T18:08:38.675787Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"svmx = []\nsvmy = []\n\nytr = []\ncury = y_train.detach().cpu().numpy()\nxtr1 = []\nxtr2 = []\nfor i in range(len(cury)):\n#     if yyyyy[i] == 0:\n    ytr.append(cury[i])\n    xtr1.append(X_train_claim[i].detach().cpu().numpy())\n    xtr2.append(X_train_ss[i].detach().cpu().numpy())\n#     svmx.append(X_train_ss[i].detach().cpu().numpy().tolist())\n    \nmodel1.eval()\nmodel2.eval()\nwith torch.no_grad():\n    p1 = model1(torch.tensor(np.array(xtr1)).to(device))\n    p1 = (p1 > 0.5).to('cpu').int().squeeze().numpy().tolist()\n    p2 = model2(torch.tensor(np.array(xtr2)).to(device))\n    p2 = (p2 > 0.5).to('cpu').int().squeeze().numpy().tolist()\n#     aaa = X_train_ss[i].detach().cpu().numpy().tolist().copy()\n    svmx = [X_train_claim[i].detach().cpu().numpy().tolist() + [p1[i], p2[i]] for i in range(len(p1))]\n    \n    Y_TEST = torch.tensor(np.array(ytr))\n    \n\n    print(classification_report(Y_TEST, p1))\n    print(confusion_matrix(Y_TEST, p1))\n    print(classification_report(Y_TEST, p2))\n    print(confusion_matrix(Y_TEST, p2))","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:25:55.807099Z","iopub.execute_input":"2023-04-01T12:25:55.808435Z","iopub.status.idle":"2023-04-01T12:25:56.868155Z","shell.execute_reply.started":"2023-04-01T12:25:55.808382Z","shell.execute_reply":"2023-04-01T12:25:56.866653Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.94      0.97      0.95      4705\n         1.0       0.96      0.92      0.94      3894\n\n    accuracy                           0.95      8599\n   macro avg       0.95      0.95      0.95      8599\nweighted avg       0.95      0.95      0.95      8599\n\n[[4555  150]\n [ 301 3593]]\n              precision    recall  f1-score   support\n\n         0.0       0.94      0.94      0.94      4705\n         1.0       0.93      0.93      0.93      3894\n\n    accuracy                           0.94      8599\n   macro avg       0.93      0.93      0.93      8599\nweighted avg       0.94      0.94      0.94      8599\n\n[[4429  276]\n [ 279 3615]]\n","output_type":"stream"}]},{"cell_type":"code","source":"906x62 60 - sentence, 2 - preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(svmx).shape","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:26:58.747934Z","iopub.execute_input":"2023-03-24T18:26:58.748322Z","iopub.status.idle":"2023-03-24T18:26:58.760131Z","shell.execute_reply.started":"2023-03-24T18:26:58.748269Z","shell.execute_reply":"2023-03-24T18:26:58.758972Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"(905, 62)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC()\nclf.fit(svmx, ytr)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:30:30.638370Z","iopub.execute_input":"2023-04-01T12:30:30.639922Z","iopub.status.idle":"2023-04-01T12:30:36.819329Z","shell.execute_reply.started":"2023-04-01T12:30:30.639855Z","shell.execute_reply":"2023-04-01T12:30:36.817676Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"SVC()"},"metadata":{}}]},{"cell_type":"code","source":"preds = clf.predict(svmx)\n\nprint(classification_report(ytr, preds))\nprint(confusion_matrix(ytr, preds))","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:30:38.079248Z","iopub.execute_input":"2023-04-01T12:30:38.079770Z","iopub.status.idle":"2023-04-01T12:30:42.988427Z","shell.execute_reply.started":"2023-04-01T12:30:38.079727Z","shell.execute_reply":"2023-04-01T12:30:42.986666Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.79      0.92      0.85      4705\n         1.0       0.87      0.70      0.78      3894\n\n    accuracy                           0.82      8599\n   macro avg       0.83      0.81      0.81      8599\nweighted avg       0.82      0.82      0.81      8599\n\n[[4307  398]\n [1176 2718]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\n\nwith open('svm.pkl', 'wb') as f:\n    pickle.dump(clf, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:32:12.941587Z","iopub.execute_input":"2023-04-01T12:32:12.942945Z","iopub.status.idle":"2023-04-01T12:32:12.956534Z","shell.execute_reply.started":"2023-04-01T12:32:12.942887Z","shell.execute_reply":"2023-04-01T12:32:12.954888Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\ncm = [[  3 ,123],\n [  0 ,961]]\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='g')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T04:14:07.689702Z","iopub.execute_input":"2023-03-25T04:14:07.690215Z","iopub.status.idle":"2023-03-25T04:14:07.958531Z","shell.execute_reply.started":"2023-03-25T04:14:07.690178Z","shell.execute_reply":"2023-03-25T04:14:07.957473Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"!pip show torch","metadata":{"execution":{"iopub.status.busy":"2023-04-01T12:40:30.146893Z","iopub.execute_input":"2023-04-01T12:40:30.147740Z","iopub.status.idle":"2023-04-01T12:40:44.126250Z","shell.execute_reply.started":"2023-04-01T12:40:30.147688Z","shell.execute_reply":"2023-04-01T12:40:44.124564Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Name: torch\nVersion: 1.13.0\nSummary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\nHome-page: https://pytorch.org/\nAuthor: PyTorch Team\nAuthor-email: packages@pytorch.org\nLicense: BSD-3\nLocation: /opt/conda/lib/python3.7/site-packages\nRequires: typing-extensions\nRequired-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, sentence-transformers, timm, torchaudio, torchmetrics, torchtext, torchvision\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}