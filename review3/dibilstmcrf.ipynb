{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaF22aW6XJI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b678d88-c7be-4479-ab7c-fa8f574f7365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-addons  # version >= 0.15.0 is required\n",
        "!pip install -q tensorflow\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpQZq2gSXQbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75bad2f-a788-4a96-b6a2-831ae3da545d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import datasets\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rhbS1gGXSx5"
      },
      "outputs": [],
      "source": [
        "TAG_SIZE = 2\n",
        "VOCAB_SIZE = 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zYDTOEFXTwK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def create_data_generatorr(dataset):\n",
        "  def data_generator():\n",
        "    for i in range(len(dataset)):\n",
        "      left = dataset.loc[i]['x'].split(' ')\n",
        "      right = None\n",
        "      if dataset.loc[i]['y'] == 0:\n",
        "        right = [0 for i in range(len(left))]\n",
        "      else:\n",
        "        right = [1 for i in range(len(left))]\n",
        "      yield left, right\n",
        "  \n",
        "  return data_generator\n",
        "\n",
        "df = pd.read_csv('/content/latest3.csv')\n",
        "adf = df.copy()\n",
        "ind = df[df['simple_sentence'].isna()].index\n",
        "df.loc[ind, 'simple_sentence'] = df.loc[ind, 'claim']\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "# grouped = adf.groupby('truth_value')\n",
        "\n",
        "# Sample 900 rows from each group\n",
        "# sampled = grouped.apply(lambda x: x.sample(n=566))\n",
        "\n",
        "# # Reset the index of the sampled data\n",
        "# sampled = sampled.reset_index(drop=True)\n",
        "cdf = df.copy()\n",
        "# df = sampled.copy()\n",
        "\n",
        "def getds(col):\n",
        "  global df\n",
        "  le = LabelEncoder()\n",
        "  df['truth_value'] = le.fit_transform(df['truth_value'])\n",
        "\n",
        "  xtrain, xtest, ytrain, ytest = train_test_split(df[col], df['truth_value'], test_size=0.2, random_state=42, shuffle=False)\n",
        "\n",
        "  train = pd.concat({'x': xtrain, 'y': ytrain}, axis=1)\n",
        "  train.reset_index(drop=True, inplace=True)\n",
        "  test = pd.concat({'x': xtest, 'y': ytest}, axis=1)\n",
        "  test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  splittrain = train['x'].apply(lambda x: x.split(' '))\n",
        "  splittest = test['x'].apply(lambda x: x.split(' '))\n",
        "  xtrain_tokens = tf.ragged.constant(train['x'].apply(lambda x: x.split(' ')))\n",
        "  xtrain_tokens = tf.map_fn(tf.strings.lower, xtrain_tokens)\n",
        "  xtest_tokens = tf.ragged.constant(test['x'].apply(lambda x: x.split(' ')))\n",
        "  xtest_tokens = tf.map_fn(tf.strings.lower, xtest_tokens)\n",
        "\n",
        "  trainlookup_layer = tf.keras.layers.StringLookup(max_tokens=VOCAB_SIZE, mask_token=\"[MASK]\", oov_token=\"[UNK]\")\n",
        "  trainlookup_layer.adapt(xtrain_tokens)\n",
        "  testlookup_layer = tf.keras.layers.StringLookup(max_tokens=VOCAB_SIZE, mask_token=\"[MASK]\", oov_token=\"[UNK]\")\n",
        "  testlookup_layer.adapt(xtest_tokens)\n",
        "\n",
        "\n",
        "  data_signature= (\n",
        "          tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
        "          tf.TensorSpec(shape=(None, ), dtype=tf.int32)\n",
        "  )\n",
        "\n",
        "  train_data = tf.data.Dataset.from_generator(\n",
        "      create_data_generatorr(train),\n",
        "      output_signature=data_signature\n",
        "  )\n",
        "  test_data = tf.data.Dataset.from_generator(\n",
        "      create_data_generatorr(test),\n",
        "      output_signature=data_signature\n",
        "  )\n",
        "  return train_data, test_data, trainlookup_layer, testlookup_layer\n",
        "\n",
        "tr1, te1, trll1, tell1 = getds('claim')\n",
        "tr2, te2, trll2, tell2 = getds('simple_sentence')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDi9eMJRXUZx"
      },
      "outputs": [],
      "source": [
        "def dataset_preprocess_train1(tokens, tag_ids):\n",
        "    preprocessed_tokens = preprecess_tokens_train1(tokens)\n",
        "    return preprocessed_tokens, tag_ids\n",
        "\n",
        "def preprecess_tokens_train1(tokens):\n",
        "    tokens = tf.strings.lower(tokens)\n",
        "    return trll1(tokens)\n",
        "\n",
        "def dataset_preprocess_test1(tokens, tag_ids):\n",
        "    preprocessed_tokens = preprecess_tokens_test1(tokens)\n",
        "    return preprocessed_tokens, tag_ids\n",
        "\n",
        "def preprecess_tokens_test1(tokens):\n",
        "    tokens = tf.strings.lower(tokens)\n",
        "    return tell1(tokens)\n",
        "\n",
        "def dataset_preprocess_train2(tokens, tag_ids):\n",
        "    preprocessed_tokens = preprecess_tokens_train2(tokens)\n",
        "    return preprocessed_tokens, tag_ids\n",
        "\n",
        "def preprecess_tokens_train2(tokens):\n",
        "    tokens = tf.strings.lower(tokens)\n",
        "    return trll2(tokens)\n",
        "\n",
        "def dataset_preprocess_test2(tokens, tag_ids):\n",
        "    preprocessed_tokens = preprecess_tokens_test2(tokens)\n",
        "    return preprocessed_tokens, tag_ids\n",
        "\n",
        "def preprecess_tokens_test2(tokens):\n",
        "    tokens = tf.strings.lower(tokens)\n",
        "    return tell2(tokens)\n",
        "\n",
        "BATCH_SIZE = 10000\n",
        "\n",
        "train_dataset1 = (\n",
        "    tr1.map(dataset_preprocess_train1)\n",
        "    .padded_batch(batch_size=BATCH_SIZE).cache()\n",
        ")\n",
        "test_dataset1 = (\n",
        "    te1.map(dataset_preprocess_test1)\n",
        "    .padded_batch(batch_size=BATCH_SIZE).cache()\n",
        ")\n",
        "\n",
        "train_dataset2 = (\n",
        "    tr2.map(dataset_preprocess_train2)\n",
        "    .padded_batch(batch_size=BATCH_SIZE).cache()\n",
        ")\n",
        "test_dataset2 = (\n",
        "    te2.map(dataset_preprocess_test2)\n",
        "    .padded_batch(batch_size=BATCH_SIZE).cache()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmdgA_b-XVRZ"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "def build_embedding_bilstm_crf_model(\n",
        "    vocab_size: int, embed_dims: int, lstm_unit: int, tag_size: int\n",
        ") -> tf.keras.Model:\n",
        "    x = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"x\")\n",
        "    y = tf.keras.layers.Embedding(vocab_size, embed_dims, mask_zero=True)(x)\n",
        "    y = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(lstm_unit, return_sequences=True)\n",
        "    )(y)\n",
        "    decode_sequence, potentials, sequence_length, kernel = tfa.layers.CRF(tag_size)(y)\n",
        "    return tf.keras.Model(\n",
        "        inputs=x, outputs=[decode_sequence, potentials, sequence_length, kernel]\n",
        "    )\n",
        "\n",
        "\n",
        "model1 = None\n",
        "optimizer1 = None\n",
        "model2 = None\n",
        "optimizer2 = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ILPgjqdXWc6"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def crf_loss_func(potentials, sequence_length, kernel, y):\n",
        "    crf_likelihood, _ = tfa.text.crf_log_likelihood(\n",
        "        potentials, y, sequence_length, kernel\n",
        "    )\n",
        "    # likelihood to loss\n",
        "    flat_crf_loss = -1 * crf_likelihood\n",
        "    crf_loss = tf.reduce_mean(flat_crf_loss)\n",
        "\n",
        "    return crf_loss\n",
        "\n",
        "train_loss1 = tf.keras.metrics.Mean(name=\"train_loss1\")\n",
        "train_loss2 = tf.keras.metrics.Mean(name=\"train_loss2\")\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def train_step(x, y):\n",
        "    global model1\n",
        "    global optimizer1\n",
        "    with tf.GradientTape() as tape:\n",
        "        decoded_sequence, potentials, sequence_length, kernel = model1(x)\n",
        "        crf_loss = crf_loss_func(potentials, sequence_length, kernel, y)\n",
        "        loss = crf_loss + tf.reduce_sum(model1.losses)\n",
        "    grads = tape.gradient(loss, model1.trainable_variables)\n",
        "    optimizer1.apply_gradients(zip(grads, model1.trainable_variables))\n",
        "\n",
        "    train_loss1(loss)\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def train_step2(x, y):\n",
        "    global model2\n",
        "    global optimizer2\n",
        "    with tf.GradientTape() as tape:\n",
        "        decoded_sequence, potentials, sequence_length, kernel = model2(x)\n",
        "        crf_loss = crf_loss_func(potentials, sequence_length, kernel, y)\n",
        "        loss = crf_loss + tf.reduce_sum(model2.losses)\n",
        "    grads = tape.gradient(loss, model2.trainable_variables)\n",
        "    optimizer2.apply_gradients(zip(grads, model2.trainable_variables))\n",
        "\n",
        "    train_loss2(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4guuCAdXX5Q",
        "outputId": "b05b0017-4f14-4af9-d4e4-14dc67ca3fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss1: 9.907398223876953\n",
            "Epoch 1, Loss2: 27.276826858520508\n",
            "Epoch 2, Loss1: 8.82288646697998\n",
            "Epoch 2, Loss2: 24.2470703125\n",
            "Epoch 3, Loss1: 9.924776077270508\n",
            "Epoch 3, Loss2: 23.46659278869629\n",
            "Epoch 4, Loss1: 7.072416305541992\n",
            "Epoch 4, Loss2: 17.46314811706543\n",
            "Epoch 5, Loss1: 6.746220111846924\n",
            "Epoch 5, Loss2: 17.012495040893555\n",
            "Epoch 6, Loss1: 5.6133341789245605\n",
            "Epoch 6, Loss2: 13.219807624816895\n",
            "Epoch 7, Loss1: 3.336562395095825\n",
            "Epoch 7, Loss2: 8.478212356567383\n",
            "Epoch 8, Loss1: 1.415023684501648\n",
            "Epoch 8, Loss2: 5.919432163238525\n",
            "Epoch 9, Loss1: 1.254758596420288\n",
            "Epoch 9, Loss2: 4.747345924377441\n",
            "Epoch 10, Loss1: 1.2020018100738525\n",
            "Epoch 10, Loss2: 3.011951208114624\n",
            "Epoch 11, Loss1: 0.855390191078186\n",
            "Epoch 11, Loss2: 2.551292896270752\n",
            "Epoch 12, Loss1: 0.4609343707561493\n",
            "Epoch 12, Loss2: 2.3217475414276123\n",
            "Epoch 13, Loss1: 0.30073678493499756\n",
            "Epoch 13, Loss2: 1.7955296039581299\n",
            "Epoch 14, Loss1: 0.22004500031471252\n",
            "Epoch 14, Loss2: 1.3860732316970825\n",
            "Epoch 15, Loss1: 0.20232470333576202\n",
            "Epoch 15, Loss2: 1.0908293724060059\n",
            "Epoch 16, Loss1: 0.1777237504720688\n",
            "Epoch 16, Loss2: 0.9396177530288696\n",
            "Epoch 17, Loss1: 0.14092811942100525\n",
            "Epoch 17, Loss2: 0.887259840965271\n",
            "Epoch 18, Loss1: 0.12421119213104248\n",
            "Epoch 18, Loss2: 0.7872440218925476\n",
            "Epoch 19, Loss1: 0.10816343128681183\n",
            "Epoch 19, Loss2: 0.5194805264472961\n",
            "Epoch 20, Loss1: 0.09128697961568832\n",
            "Epoch 20, Loss2: 0.4721055328845978\n"
          ]
        }
      ],
      "source": [
        "model1 = build_embedding_bilstm_crf_model(VOCAB_SIZE, 32, 64, 2)\n",
        "optimizer1 = tf.keras.optimizers.Adam(0.02)\n",
        "model2 = build_embedding_bilstm_crf_model(VOCAB_SIZE, 32, 64, 2)\n",
        "optimizer2 = tf.keras.optimizers.Adam(0.02)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "\n",
        "for epoch in range(20):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss1.reset_states()\n",
        "  train_loss2.reset_states()\n",
        "\n",
        "  for x, y in train_dataset1:\n",
        "      train_step(x, y)\n",
        "  for x, y in train_dataset2:\n",
        "      train_step2(x, y)\n",
        "  print(f\"Epoch {epoch + 1}, \" f\"Loss1: {train_loss1.result()}\")\n",
        "  print(f\"Epoch {epoch + 1}, \" f\"Loss2: {train_loss2.result()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gBXASpgav8f",
        "outputId": "6c82a9d2-8389-4384-8207-97c72c01010e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "with open('trll1.txt', 'w') as file:\n",
        "  file.write('\\n'.join(trll1.get_vocabulary(include_special_tokens=True)))\n",
        "with open('trll2.txt', 'w') as file:\n",
        "  file.write('\\n'.join(trll2.get_vocabulary(include_special_tokens=True)))\n",
        "with open('tell1.txt', 'w') as file:\n",
        "  file.write('\\n'.join(tell1.get_vocabulary(include_special_tokens=True)))\n",
        "with open('tell2.txt', 'w') as file:\n",
        "  file.write('\\n'.join(tell2.get_vocabulary(include_special_tokens=True)))\n",
        "model1.save('./nm1.h5')\n",
        "model2.save('./nm2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2_E7NfUXY8R",
        "outputId": "173fd786-ea24-44bb-fab2-f4f10f4b5a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302/302 [==============================] - 113s 373ms/step\n",
            "302/302 [==============================] - 322s 1s/step\n"
          ]
        }
      ],
      "source": [
        "# train set\n",
        "o1 = []\n",
        "o2 = []\n",
        "o = []\n",
        "oy = []\n",
        "\n",
        "def processs(x, pred):\n",
        "  res = []\n",
        "  for i in range(len(x)):\n",
        "    b = pred[i]\n",
        "    tot = (sum(b) / len(b)) * 100\n",
        "    label = 1\n",
        "    if tot <= 50:\n",
        "      label = 0\n",
        "    res.append(tot)\n",
        "  return res\n",
        "\n",
        "for x, y in train_dataset1:\n",
        "  outputs, *_ = model1.predict(x)\n",
        "  a = processs(x.numpy(), outputs)\n",
        "  o1 += a\n",
        "  oy += [p[0] for p in y.numpy()]\n",
        "  \n",
        "for x, y in train_dataset2:\n",
        "  outputs, *_ = model2.predict(x)\n",
        "  a = processs(x.numpy(), outputs)\n",
        "  o2 += a\n",
        "\n",
        "for i in range(len(o1)):\n",
        "  o.append([o1[i].item() / 100, o2[i].item() / 100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ0N3MZEd1og"
      },
      "outputs": [],
      "source": [
        "\n",
        "# test set\n",
        "to = []\n",
        "toy = []\n",
        "\n",
        "for x, y in test_dataset1:\n",
        "  toy += [p[0] for p in y.numpy()]\n",
        "  to += [[p[0], p[0]] for p in y.numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRZ8eA2sePVi",
        "outputId": "a5915cf5-5cc8-4323-9d7e-e3ac03ced873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9645, 2412)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(np.array(o)), len(np.array(to))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlJFl-h7ZeUg",
        "outputId": "284fe0fd-1d5d-43d6-a874-40e0644f85fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "302/302 [==============================] - 8s 27ms/step - loss: 0.5968 - accuracy: 0.9971 - val_loss: 0.3775 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "302/302 [==============================] - 8s 28ms/step - loss: 0.5688 - accuracy: 0.9801 - val_loss: 0.3295 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "302/302 [==============================] - 8s 26ms/step - loss: 0.5448 - accuracy: 0.9600 - val_loss: 0.2966 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "302/302 [==============================] - 9s 30ms/step - loss: 0.5230 - accuracy: 0.9387 - val_loss: 0.2745 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "302/302 [==============================] - 8s 27ms/step - loss: 0.5030 - accuracy: 0.9372 - val_loss: 0.2573 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "302/302 [==============================] - 8s 26ms/step - loss: 0.4842 - accuracy: 0.9381 - val_loss: 0.2429 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "302/302 [==============================] - 9s 29ms/step - loss: 0.4667 - accuracy: 0.9379 - val_loss: 0.2311 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "302/302 [==============================] - 8s 25ms/step - loss: 0.4502 - accuracy: 0.9384 - val_loss: 0.2213 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "302/302 [==============================] - 8s 27ms/step - loss: 0.4346 - accuracy: 0.9426 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "302/302 [==============================] - 9s 29ms/step - loss: 0.4199 - accuracy: 0.9528 - val_loss: 0.2043 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b4f11d730>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "model4 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model4.fit(x=np.array(o), y=np.array(oy), validation_data=(np.array(to), np.array(toy)), epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvjc3gnxdz8v",
        "outputId": "2eb8645a-abff-4af4-8194-7996ac05d62d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 22s 295ms/step\n",
            "76/76 [==============================] - 45s 596ms/step\n"
          ]
        }
      ],
      "source": [
        "m1ox = []\n",
        "m1oy = []\n",
        "m2ox = []\n",
        "m2oy = []\n",
        "fy = []\n",
        "\n",
        "for x, y in test_dataset1:\n",
        "  outputs, *_ = model1.predict(x)\n",
        "  a = processs(x.numpy(), outputs)\n",
        "  m1ox += a\n",
        "  m1oy += [p[0] for p in y.numpy()]\n",
        "  fy.extend([p[0] for p in y.numpy()])\n",
        "  \n",
        "for x, y in test_dataset2:\n",
        "  outputs, *_ = model2.predict(x)\n",
        "  m2ox = processs(x.numpy(), outputs)\n",
        "  m2oy += a\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GU5SHCaK-G3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_model1_trainpredy = [int(i > 55) for i in o1]\n",
        "report_model2_trainpredy = [int(i > 55) for i in o2]\n",
        "report_model1_testpredy = [int(i > 55) for i in m1ox]\n",
        "report_model2_testpredy = [int(i > 55) for i in m2ox]\n",
        "# report_y = []\n",
        "# for x, y in test_dataset1:\n",
        "#   outputs, *_ = model1.predict(x)\n",
        "#   a = processs(x.numpy(), outputs)\n",
        "#   print(len(a), y.shape)\n",
        "\n",
        "  \n",
        "# for x, y in test_dataset2:\n",
        "#   outputs, *_ = model2.predict(x)\n",
        "#   a = processs(x.numpy(), outputs)\n",
        "#   print(len(a), y.shape)\n",
        "\n",
        "print(classification_report(oy, report_model1_trainpredy))\n",
        "print(confusion_matrix(oy, report_model1_trainpredy), '\\n\\n')\n",
        "print(classification_report(oy, report_model2_trainpredy))\n",
        "print(confusion_matrix(oy, report_model2_trainpredy))\n",
        "\n",
        "print(classification_report(fy, report_model1_testpredy))\n",
        "print(confusion_matrix(fy, report_model1_testpredy), '\\n\\n')\n",
        "print(classification_report(fy, report_model2_testpredy))\n",
        "print(confusion_matrix(fy, report_model2_testpredy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0leEIH18ILL",
        "outputId": "60abfd4a-f0dc-4ba0-b076-8cbaef504a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.69      5069\n",
            "           1       1.00      0.01      0.03      4576\n",
            "\n",
            "    accuracy                           0.53      9645\n",
            "   macro avg       0.76      0.51      0.36      9645\n",
            "weighted avg       0.75      0.53      0.38      9645\n",
            "\n",
            "[[5069    0]\n",
            " [4508   68]] \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.69      5069\n",
            "           1       1.00      0.00      0.01      4576\n",
            "\n",
            "    accuracy                           0.53      9645\n",
            "   macro avg       0.76      0.50      0.35      9645\n",
            "weighted avg       0.75      0.53      0.37      9645\n",
            "\n",
            "[[5069    0]\n",
            " [4560   16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.99      0.71      1250\n",
            "           1       0.95      0.14      0.25      1162\n",
            "\n",
            "    accuracy                           0.58      2412\n",
            "   macro avg       0.75      0.57      0.48      2412\n",
            "weighted avg       0.75      0.58      0.49      2412\n",
            "\n",
            "[[1242    8]\n",
            " [ 997  165]] \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.69      1250\n",
            "           1       0.97      0.03      0.06      1162\n",
            "\n",
            "    accuracy                           0.53      2412\n",
            "   macro avg       0.75      0.52      0.38      2412\n",
            "weighted avg       0.74      0.53      0.39      2412\n",
            "\n",
            "[[1249    1]\n",
            " [1124   38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpETkyXJgUI5"
      },
      "outputs": [],
      "source": [
        "mox = []\n",
        "\n",
        "for i in range(len(m1ox)):\n",
        "  mox.append([m1ox[i].item() / 100, m2ox[i].item() / 100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lro9f1hf1Xq",
        "outputId": "0f7814b7-f040-4789-a880-93ccf47f4c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 0.1\n",
            "46/76 [=================>............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1250\n",
            "           1       0.48      1.00      0.65      1162\n",
            "\n",
            "    accuracy                           0.48      2412\n",
            "   macro avg       0.24      0.50      0.33      2412\n",
            "weighted avg       0.23      0.48      0.31      2412\n",
            "\n",
            "[[   0 1250]\n",
            " [   0 1162]] \n",
            "\n",
            "\n",
            "for 0.15\n",
            "46/76 [=================>............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1250\n",
            "           1       0.48      1.00      0.65      1162\n",
            "\n",
            "    accuracy                           0.48      2412\n",
            "   macro avg       0.24      0.50      0.33      2412\n",
            "weighted avg       0.23      0.48      0.31      2412\n",
            "\n",
            "[[   0 1250]\n",
            " [   0 1162]] \n",
            "\n",
            "\n",
            "for 0.2\n",
            "47/76 [=================>............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1250\n",
            "           1       0.48      1.00      0.65      1162\n",
            "\n",
            "    accuracy                           0.48      2412\n",
            "   macro avg       0.24      0.50      0.33      2412\n",
            "weighted avg       0.23      0.48      0.31      2412\n",
            "\n",
            "[[   0 1250]\n",
            " [   0 1162]] \n",
            "\n",
            "\n",
            "for 0.25\n",
            "20/76 [======>.......................] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1250\n",
            "           1       0.48      1.00      0.65      1162\n",
            "\n",
            "    accuracy                           0.48      2412\n",
            "   macro avg       0.24      0.50      0.33      2412\n",
            "weighted avg       0.23      0.48      0.31      2412\n",
            "\n",
            "[[   0 1250]\n",
            " [   0 1162]] \n",
            "\n",
            "\n",
            "for 0.3\n",
            "46/76 [=================>............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1250\n",
            "           1       0.48      1.00      0.65      1162\n",
            "\n",
            "    accuracy                           0.48      2412\n",
            "   macro avg       0.24      0.50      0.33      2412\n",
            "weighted avg       0.23      0.48      0.31      2412\n",
            "\n",
            "[[   0 1250]\n",
            " [   0 1162]] \n",
            "\n",
            "\n",
            "for 0.35\n",
            "37/76 [=============>................] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.14      0.24      1250\n",
            "           1       0.51      0.95      0.66      1162\n",
            "\n",
            "    accuracy                           0.53      2412\n",
            "   macro avg       0.63      0.55      0.45      2412\n",
            "weighted avg       0.63      0.53      0.44      2412\n",
            "\n",
            "[[ 177 1073]\n",
            " [  58 1104]] \n",
            "\n",
            "\n",
            "for 0.4\n",
            "38/76 [==============>...............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.34      0.48      1250\n",
            "           1       0.56      0.90      0.69      1162\n",
            "\n",
            "    accuracy                           0.61      2412\n",
            "   macro avg       0.68      0.62      0.58      2412\n",
            "weighted avg       0.68      0.61      0.58      2412\n",
            "\n",
            "[[ 425  825]\n",
            " [ 112 1050]] \n",
            "\n",
            "\n",
            "for 0.45\n",
            "46/76 [=================>............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.47      0.58      1250\n",
            "           1       0.60      0.84      0.70      1162\n",
            "\n",
            "    accuracy                           0.65      2412\n",
            "   macro avg       0.68      0.65      0.64      2412\n",
            "weighted avg       0.68      0.65      0.64      2412\n",
            "\n",
            "[[591 659]\n",
            " [191 971]] \n",
            "\n",
            "\n",
            "for 0.5\n",
            "39/76 [==============>...............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.63      0.68      1250\n",
            "           1       0.66      0.76      0.70      1162\n",
            "\n",
            "    accuracy                           0.69      2412\n",
            "   macro avg       0.70      0.69      0.69      2412\n",
            "weighted avg       0.70      0.69      0.69      2412\n",
            "\n",
            "[[787 463]\n",
            " [282 880]] \n",
            "\n",
            "\n",
            "for 0.55\n",
            "44/76 [================>.............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.77      0.75      1250\n",
            "           1       0.74      0.68      0.71      1162\n",
            "\n",
            "    accuracy                           0.73      2412\n",
            "   macro avg       0.73      0.73      0.73      2412\n",
            "weighted avg       0.73      0.73      0.73      2412\n",
            "\n",
            "[[968 282]\n",
            " [369 793]] \n",
            "\n",
            "\n",
            "for 0.6\n",
            "49/76 [==================>...........] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.86      0.77      1250\n",
            "           1       0.80      0.61      0.69      1162\n",
            "\n",
            "    accuracy                           0.74      2412\n",
            "   macro avg       0.75      0.73      0.73      2412\n",
            "weighted avg       0.75      0.74      0.73      2412\n",
            "\n",
            "[[1071  179]\n",
            " [ 451  711]] \n",
            "\n",
            "\n",
            "for 0.65\n",
            "42/76 [===============>..............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.92      0.78      1250\n",
            "           1       0.86      0.53      0.66      1162\n",
            "\n",
            "    accuracy                           0.73      2412\n",
            "   macro avg       0.77      0.73      0.72      2412\n",
            "weighted avg       0.77      0.73      0.72      2412\n",
            "\n",
            "[[1153   97]\n",
            " [ 546  616]] \n",
            "\n",
            "\n",
            "for 0.7\n",
            "47/76 [=================>............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.96      0.78      1250\n",
            "           1       0.91      0.46      0.61      1162\n",
            "\n",
            "    accuracy                           0.72      2412\n",
            "   macro avg       0.78      0.71      0.70      2412\n",
            "weighted avg       0.78      0.72      0.70      2412\n",
            "\n",
            "[[1194   56]\n",
            " [ 623  539]] \n",
            "\n",
            "\n",
            "for 0.75\n",
            "40/76 [==============>...............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.98      0.77      1250\n",
            "           1       0.95      0.40      0.56      1162\n",
            "\n",
            "    accuracy                           0.70      2412\n",
            "   macro avg       0.79      0.69      0.67      2412\n",
            "weighted avg       0.79      0.70      0.67      2412\n",
            "\n",
            "[[1225   25]\n",
            " [ 697  465]] \n",
            "\n",
            "\n",
            "for 0.8\n",
            "42/76 [===============>..............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.98      0.75      1250\n",
            "           1       0.95      0.32      0.48      1162\n",
            "\n",
            "    accuracy                           0.67      2412\n",
            "   macro avg       0.78      0.65      0.62      2412\n",
            "weighted avg       0.77      0.67      0.62      2412\n",
            "\n",
            "[[1231   19]\n",
            " [ 787  375]] \n",
            "\n",
            "\n",
            "for 0.85\n",
            "47/76 [=================>............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.99      0.74      1250\n",
            "           1       0.96      0.26      0.41      1162\n",
            "\n",
            "    accuracy                           0.64      2412\n",
            "   macro avg       0.77      0.62      0.57      2412\n",
            "weighted avg       0.77      0.64      0.58      2412\n",
            "\n",
            "[[1237   13]\n",
            " [ 862  300]] \n",
            "\n",
            "\n",
            "for 0.9\n",
            "44/76 [================>.............] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.72      1250\n",
            "           1       0.97      0.17      0.29      1162\n",
            "\n",
            "    accuracy                           0.60      2412\n",
            "   macro avg       0.77      0.58      0.51      2412\n",
            "weighted avg       0.76      0.60      0.51      2412\n",
            "\n",
            "[[1244    6]\n",
            " [ 963  199]] \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "for i in range(10, 95, 5):\n",
        "  i /= 100\n",
        "  print('for', i)\n",
        "  outs = model4.predict(mox) > i\n",
        "  outs = outs.flatten()\n",
        "\n",
        "  print(classification_report(fy, outs))\n",
        "  print(confusion_matrix(fy, outs), '\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zIQJRRfg4Ex",
        "outputId": "c245992c-803c-43cb-f037-a7d9e7aa15fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "60 81\n"
          ]
        }
      ],
      "source": [
        "texmax, trxmax = 0, 0\n",
        "for x, y in test_dataset1:\n",
        "  # print(x.shape)\n",
        "  texmax = max(texmax, x.shape[1])\n",
        "print('\\n')\n",
        "for x, y in train_dataset1:\n",
        "  # print(x.shape)\n",
        "  trxmax = max(trxmax, x.shape[1])\n",
        "print(texmax, trxmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpV40lm-qItf",
        "outputId": "6ebdda7c-0de1-4f65-b49c-99684386dd8a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302/302 [==============================] - 116s 384ms/step\n",
            "302/302 [==============================] - 326s 1s/step\n",
            "76/76 [==============================] - 23s 298ms/step\n",
            "76/76 [==============================] - 44s 578ms/step\n"
          ]
        }
      ],
      "source": [
        "mo1 = tf.keras.models.load_model('/content/nm1.h5')\n",
        "mo2 = tf.keras.models.load_model('/content/nm2.h5')\n",
        "\n",
        "mo1oxtr = []\n",
        "mo1oytr = []\n",
        "mo2oxtr = []\n",
        "mo2oytr = []\n",
        "ftrysvm = []\n",
        "mo1oxte = []\n",
        "mo1oyte = []\n",
        "mo2oxte = []\n",
        "mo2oyte = []\n",
        "fteysvm = []\n",
        "\n",
        "def processs(x, pred):\n",
        "  res = []\n",
        "  for i in range(len(x)):\n",
        "    b = pred[i]\n",
        "    tot = (sum(b) / len(b)) * 100\n",
        "    label = 1\n",
        "    if tot <= 50:\n",
        "      label = 0\n",
        "    res.append(tot)\n",
        "  return res\n",
        "\n",
        "for x, y in train_dataset1:\n",
        "  outputs, *_ = mo1.predict(x)\n",
        "  a = processs(x.numpy(), outputs)\n",
        "  mo1oxtr += a\n",
        "  mo1oytr += [p[0] for p in y.numpy()]\n",
        "  ftrysvm.extend([p[0] for p in y.numpy()])\n",
        "  \n",
        "for x, y in train_dataset2:\n",
        "  outputs, *_ = mo2.predict(x)\n",
        "  mo2oxtr = processs(x.numpy(), outputs)\n",
        "  mo2oytr += a\n",
        "\n",
        "for x, y in test_dataset1:\n",
        "  outputs, *_ = mo1.predict(x)\n",
        "  a = processs(x.numpy(), outputs)\n",
        "  mo1oxte += a\n",
        "  mo1oyte += [p[0] for p in y.numpy()]\n",
        "  fteysvm.extend([p[0] for p in y.numpy()])\n",
        "  \n",
        "for x, y in test_dataset2:\n",
        "  outputs, *_ = mo2.predict(x)\n",
        "  mo2oxte = processs(x.numpy(), outputs)\n",
        "  mo2oyte += a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLktVI9yqtwO"
      },
      "outputs": [],
      "source": [
        "svmtrx = None\n",
        "svmtry = None\n",
        "svmtex = None\n",
        "svmtey = None\n",
        "for x, y in train_dataset1:\n",
        "  svmtrx = x\n",
        "  svmtry = np.array([p[0] for p in y.numpy()])\n",
        "for x, y in test_dataset1:\n",
        "  svmtex = x\n",
        "  svmtey = np.array([p[0] for p in y.numpy()])\n",
        "svmtex = tf.pad(svmtex, [[0, 0], [0, svmtrx.shape[1] - svmtex.shape[1]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5U4StJH0HWp",
        "outputId": "f2297ad7-bb7a-41c3-e18b-dfac2c5790d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9645,\n",
              " 9645,\n",
              " 9645,\n",
              " 9645,\n",
              " 2412,\n",
              " 2412,\n",
              " 2412,\n",
              " 2412,\n",
              " TensorShape([9645, 81]),\n",
              " TensorShape([2412, 81]),\n",
              " (9645,),\n",
              " (2412,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(mo1oxtr), len(mo1oytr), len(mo2oxtr), len(mo2oytr), len(mo1oxte), len(mo1oyte), len(mo2oxte), len(mo2oyte), svmtrx.shape, svmtex.shape, svmtry.shape, svmtey.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gLnW1xY1Qr0"
      },
      "outputs": [],
      "source": [
        "nsvmtrx = []\n",
        "nsvmtry = []\n",
        "nsvmtex = []\n",
        "nsvmtey = []\n",
        "\n",
        "for i in range(svmtrx.shape[0]):\n",
        "  nsvmtrx.append(list(svmtrx[i].numpy()) + [mo1oxtr[i], mo2oxtr[i]])\n",
        "  nsvmtry.append(svmtry[i])\n",
        "for i in range(svmtex.shape[0]):\n",
        "  nsvmtex.append(list(svmtex[i].numpy()) + [mo1oxte[i], mo2oxte[i]])\n",
        "  nsvmtey.append(svmtey[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Cnfjid5JHj",
        "outputId": "8e6752f3-5557-4d8f-8876-0c41aed04d79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9645, 83, 9645, 2412, 83, 2412)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(nsvmtrx), len(nsvmtrx[0]), len(nsvmtry), len(nsvmtex), len(nsvmtex[0]), len(nsvmtey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yHxZaUatVuL",
        "outputId": "55061af8-4647-4b4d-dfa6-2ed778405c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.92      0.82      5069\n",
            "           1       0.88      0.64      0.74      4576\n",
            "\n",
            "    accuracy                           0.79      9645\n",
            "   macro avg       0.81      0.78      0.78      9645\n",
            "weighted avg       0.81      0.79      0.78      9645\n",
            "\n",
            "[[4666  403]\n",
            " [1642 2934]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(probability=True)\n",
        "clf.fit(nsvmtrx, nsvmtry)\n",
        "\n",
        "preds = clf.predict(nsvmtrx)\n",
        "\n",
        "print(classification_report(nsvmtry, preds))\n",
        "print(confusion_matrix(nsvmtry, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sWZyLxAxGFv",
        "outputId": "9fc1f7ff-bd02-43ec-e8f0-6475a330583e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.90      0.80      1250\n",
            "           1       0.85      0.62      0.72      1162\n",
            "\n",
            "    accuracy                           0.77      2412\n",
            "   macro avg       0.79      0.76      0.76      2412\n",
            "weighted avg       0.78      0.77      0.76      2412\n",
            "\n",
            "[[1125  125]\n",
            " [ 437  725]]\n"
          ]
        }
      ],
      "source": [
        "preds = clf.predict(nsvmtex)\n",
        "\n",
        "print(classification_report(nsvmtey, preds))\n",
        "print(confusion_matrix(nsvmtey, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu2kmvt54Tbw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}